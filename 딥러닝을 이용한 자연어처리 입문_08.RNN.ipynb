{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e5e5177",
   "metadata": {},
   "source": [
    "<img src=\"https://wikidocs.net/images/page/22886/rnn_image6between7.PNG\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e028d0-9ba9-4757-9fa7-e59d14e20106",
   "metadata": {},
   "source": [
    "# Keras RNN 기초"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8266d5c5",
   "metadata": {},
   "source": [
    "model.add(SimpleRNN(hidden_units, input_shape=(timesteps, input_dim)))  \n",
    "model.add(SimpleRNN(hidden_units, input_length=M, input_dim=N))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c54b79f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "130777b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3a68c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5)\n"
     ]
    }
   ],
   "source": [
    "train_X = [[0.1, 4.2, 1.5, 1.1, 2.8], [1.0, 3.1, 2.5, 0.7, 1.1], [0.3, 2.1, 1.5, 2.1, 0.1], [2.2, 1.4, 0.5, 0.9, 1.1]]\n",
    "print(np.shape(train_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9e3c01",
   "metadata": {},
   "source": [
    "→ 2D 텐서(일반적인 행렬)이기 때문에 3D 텐서로 변환하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c52f9e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 5)\n"
     ]
    }
   ],
   "source": [
    "train_X = [[[0.1, 4.2, 1.5, 1.1, 2.8], [1.0, 3.1, 2.5, 0.7, 1.1], [0.3, 2.1, 1.5, 2.1, 0.1], [2.2, 1.4, 0.5, 0.9, 1.1]]]\n",
    "train_X = np.array(train_X, dtype=np.float32)\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa97d3f",
   "metadata": {},
   "source": [
    "(batch_size, timesteps, input_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badf24c1",
   "metadata": {},
   "source": [
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc81a40",
   "metadata": {},
   "source": [
    "# SimpleRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de3abec",
   "metadata": {},
   "source": [
    "return_sequences = True → SimpleRNN의 모든 시점의 은닉 상태를 출력함(many-to-many 문제 해결)  \n",
    "return_sequences = False → SimpleRNN의 마지막 시점만의 은닉 상태를 출력함(many-to-one 문제 해결)\n",
    "\n",
    "return_state = True → (return_sequences와 관계없이) 마지막 시점의 은닉 상태를 출력함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04feddb",
   "metadata": {},
   "source": [
    "<img src=\"https://wikidocs.net/images/page/22886/rnn_image8_ver2.PNG\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1987bc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271e58f3",
   "metadata": {},
   "source": [
    "1. (return_sequences, return_state) = (False, False)인 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5aa6841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\Lib\\site-packages\\keras\\src\\layers\\rnn\\simple_rnn.py:130: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "hidden state : [[ 0.99779236  0.98238194 -0.96625775]], shape : (1, 3)\n"
     ]
    }
   ],
   "source": [
    "rnn = SimpleRNN(3) # SimpleRNN(units, return_sequences=Flase, return_state=False)\n",
    "hidden_state = rnn(train_X)\n",
    "\n",
    "print('hidden state : {}, shape : {}'.format(hidden_state, hidden_state.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faa4b33",
   "metadata": {},
   "source": [
    "마지막 시점의 은닉 상태가 출력되는 것을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4882ca",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2926cc0",
   "metadata": {},
   "source": [
    "2. (return_sequences, return_state) = (True, False)인 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3eea288a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states : [[[ 0.97294873 -0.9986201  -0.9852192 ]\n",
      "  [ 0.7791255   0.23681597 -0.98734236]\n",
      "  [ 0.8989133  -0.2689766  -0.96348786]\n",
      "  [ 0.9934039  -0.73291045 -0.8300911 ]]], shape : (1, 4, 3)\n"
     ]
    }
   ],
   "source": [
    "rnn = SimpleRNN(3, return_sequences=True)\n",
    "hidden_states =  rnn(train_X)\n",
    "\n",
    "print('hidden states : {}, shape : {}'.format(hidden_states, hidden_states.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d930851c",
   "metadata": {},
   "source": [
    "모든 시점의 은닉 상태가 출력되는 것을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53740804",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be2f6fb",
   "metadata": {},
   "source": [
    "3. (return_sequences, return_state) = (True, True)인 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91c8f1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states : [[[ 0.8806072   0.8279266   0.9968007 ]\n",
      "  [ 0.22305678 -0.04166216  0.9709169 ]\n",
      "  [ 0.5725307   0.83857965  0.5900981 ]\n",
      "  [-0.8363692   0.90119135  0.99560153]]], shape : (1, 4, 3)\n",
      "last hidden state : [[-0.8363692   0.90119135  0.99560153]], shape : (1, 3)\n"
     ]
    }
   ],
   "source": [
    "rnn = SimpleRNN(3, return_sequences=True, return_state=True)\n",
    "hidden_states, last_state = rnn(train_X)\n",
    "\n",
    "print('hidden states : {}, shape : {}'.format(hidden_states, hidden_states.shape))\n",
    "print('last hidden state : {}, shape : {}'.format(last_state, last_state.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34d71c0",
   "metadata": {},
   "source": [
    "모든 시점의 은닉 상태와 마지막 은닉 상태를 출력한 것을 확인할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5808c709",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dda79f0",
   "metadata": {},
   "source": [
    "4. (return_sequences, return_state) = (False, True)인 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42d6e1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state : [[-0.96820366  0.21530943 -0.49535704]], shape : (1, 3)\n",
      "last hidden state : [[-0.96820366  0.21530943 -0.49535704]], shape : (1, 3)\n"
     ]
    }
   ],
   "source": [
    "rnn = SimpleRNN(3, return_sequences=False, return_state=True)\n",
    "hidden_state, last_state = rnn(train_X)\n",
    "\n",
    "print('hidden state : {}, shape : {}'.format(hidden_state, hidden_state.shape))\n",
    "print('last hidden state : {}, shape : {}'.format(last_state, last_state.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c97684",
   "metadata": {},
   "source": [
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4685aa82",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd16e135",
   "metadata": {},
   "source": [
    "1. (return_sequences, return_state) = (False, True)인 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9eb6594",
   "metadata": {},
   "source": [
    "→ SimpleRNN과 달리 return_state=True라면 last hidden state와 cell state 둘 다 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b4ca669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state : [[ 0.18465963 -0.19729702 -0.27784726]], shape : (1, 3)\n",
      "last hidden state : [[ 0.18465963 -0.19729702 -0.27784726]], shape : (1, 3)\n",
      "last cell state : [[ 0.21178982 -0.9648578  -0.55450886]], shape : (1, 3)\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(3, return_sequences=False, return_state=True)\n",
    "hidden_state, last_state, last_cell_state = lstm(train_X)\n",
    "\n",
    "print('hidden state : {}, shape : {}'.format(hidden_state, hidden_state.shape))\n",
    "print('last hidden state : {}, shape : {}'.format(last_state, last_state.shape))\n",
    "print('last cell state : {}, shape : {}'.format(last_cell_state, last_cell_state.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74712c95",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e07349",
   "metadata": {},
   "source": [
    "2. (return_sequences, return_state) = (True, True)인 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8be9cea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states : [[[ 0.2603413   0.09060887 -0.1035516 ]\n",
      "  [ 0.6696156   0.16278873 -0.21831824]\n",
      "  [ 0.44381034  0.14252222 -0.3680046 ]\n",
      "  [ 0.7299013   0.40467337 -0.29832104]]], shape : (1, 4, 3)\n",
      "last hidden state : [[ 0.7299013   0.40467337 -0.29832104]], shape : (1, 3)\n",
      "last cell state : [[ 1.9762206   0.5365603  -0.47050995]], shape : (1, 3)\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(3, return_sequences=True, return_state=True)\n",
    "hidden_state, last_state, last_cell_state = lstm(train_X)\n",
    "\n",
    "print('hidden states : {}, shape : {}'.format(hidden_state, hidden_state.shape))\n",
    "print('last hidden state : {}, shape : {}'.format(last_state, last_state.shape))\n",
    "print('last cell state : {}, shape : {}'.format(last_cell_state, last_cell_state.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590b8b4a",
   "metadata": {},
   "source": [
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719a9664",
   "metadata": {},
   "source": [
    "# Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7e0d4b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92506e4",
   "metadata": {},
   "source": [
    "출력되는 은닉 상태의 값 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fc7b33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_init = tf.keras.initializers.Constant(value=0.1)\n",
    "b_init = tf.keras.initializers.Constant(value=0)\n",
    "r_init = tf.keras.initializers.Constant(value=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b5adec",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf7808e",
   "metadata": {},
   "source": [
    "1. (return_sequences, return_state) = (False, True)인 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07040886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state : [[0.63031393 0.63031393 0.63031393 0.7038734  0.7038734  0.7038734 ]], shape : (1, 6)\n",
      "forward state : [[0.63031393 0.63031393 0.63031393]], shape : (1, 3)\n",
      "backward state : [[0.7038734 0.7038734 0.7038734]], shape : (1, 3)\n"
     ]
    }
   ],
   "source": [
    "bilstm = Bidirectional(LSTM(3, return_sequences=False, return_state=True,\n",
    "                            kernel_initializer=k_init, bias_initializer=b_init, recurrent_initializer=r_init))\n",
    "hidden_states, forward_h, forward_c, backward_h, backward_c = bilstm(train_X)\n",
    "\n",
    "print('hidden state : {}, shape : {}'.format(hidden_states, hidden_states.shape))\n",
    "print('forward state : {}, shape : {}'.format(forward_h, forward_h.shape))\n",
    "print('backward state : {}, shape : {}'.format(backward_h, backward_h.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4177ab",
   "metadata": {},
   "source": [
    "→ hidden state = 정방향 LSTM 마지막 시점의 은닉 상태 + 역방향 LSTM 첫번째 시점의 은닉 상태"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364126b5",
   "metadata": {},
   "source": [
    "→ 그림으로 이해해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdd7c77",
   "metadata": {},
   "source": [
    "<img src=\"https://wikidocs.net/images/page/94748/bilstm3.PNG\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8ec825",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d31798",
   "metadata": {},
   "source": [
    "2. (return_sequences, return_state) = (True, True)인 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5281ee7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states : [[[0.35906473 0.35906473 0.35906473 0.7038734  0.7038734  0.7038734 ]\n",
      "  [0.5511133  0.5511133  0.5511133  0.58863586 0.58863586 0.58863586]\n",
      "  [0.59115756 0.59115756 0.59115756 0.3951699  0.3951699  0.3951699 ]\n",
      "  [0.63031393 0.63031393 0.63031393 0.21942244 0.21942244 0.21942244]]], shape : (1, 4, 6)\n",
      "forward state : [[0.63031393 0.63031393 0.63031393]], shape : (1, 3)\n",
      "backward state : [[0.7038734 0.7038734 0.7038734]], shape : (1, 3)\n"
     ]
    }
   ],
   "source": [
    "bilstm = Bidirectional(LSTM(3, return_sequences=True, return_state=True,\n",
    "                           kernel_initializer=k_init, bias_initializer=b_init, recurrent_initializer=r_init))\n",
    "hidden_states, forward_h, forward_c, backward_h, backward_c = bilstm(train_X)\n",
    "\n",
    "print('hidden states : {}, shape : {}'.format(hidden_states, hidden_states.shape))\n",
    "print('forward state : {}, shape : {}'.format(forward_h, forward_h.shape))\n",
    "print('backward state : {}, shape : {}'.format(backward_h, backward_h.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49296213",
   "metadata": {},
   "source": [
    "→ 그림으로 이해해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44e9a1e",
   "metadata": {},
   "source": [
    "<img src=\"https://wikidocs.net/images/page/94748/bilstm1.PNG\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0142de",
   "metadata": {},
   "source": [
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef02a902",
   "metadata": {},
   "source": [
    "# SimpleRNN을 이용한 텍스트 생성(Text Generation using RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2974bed8",
   "metadata": {},
   "source": [
    "1. 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76c7b809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a304af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"경마장에 있는 말이 뛰고 있다\\n\n",
    "그의 말이 법이다\\n\n",
    "가는 말이 고와야 오는 말이 곱다\\n\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbc89e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 12\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text]) # text 각각에 index 부여\n",
    "vocab_size = len(tokenizer.word_index)+1\n",
    "print('단어 집합의 크기 : %d' %vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d09a7d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'말이': 1, '경마장에': 2, '있는': 3, '뛰고': 4, '있다': 5, '그의': 6, '법이다': 7, '가는': 8, '고와야': 9, '오는': 10, '곱다': 11}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dd0390",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f76589",
   "metadata": {},
   "source": [
    "(1) 훈련 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23c82966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습에 사용할 샘플의 갯수 : 11\n"
     ]
    }
   ],
   "source": [
    "sequences = []\n",
    "for line in text.split('\\n'):\n",
    "    encoded = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(encoded)):\n",
    "        sequence = encoded[:i+1]\n",
    "        sequences.append(sequence)\n",
    "        \n",
    "print('학습에 사용할 샘플의 갯수 : %d' %len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34913725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3], [2, 3, 1], [2, 3, 1, 4], [2, 3, 1, 4, 5], [6, 1], [6, 1, 7], [8, 1], [8, 1, 9], [8, 1, 9, 10], [8, 1, 9, 10, 1], [8, 1, 9, 10, 1, 11]]\n"
     ]
    }
   ],
   "source": [
    "print(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69762a54",
   "metadata": {},
   "source": [
    "Eg.  \n",
    "[2, 3] : 경마장에 있는  \n",
    "[2, 3, 1] : 경마장에 있는 말이"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c189cf1c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d874e58",
   "metadata": {},
   "source": [
    "(2) 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f9712bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 최대 길이 : 6\n"
     ]
    }
   ],
   "source": [
    "max_len = max(len(l) for l in sequences)\n",
    "print('샘플의 최대 길이 : {}'.format(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38a569cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  2  3]\n",
      " [ 0  0  0  2  3  1]\n",
      " [ 0  0  2  3  1  4]\n",
      " [ 0  2  3  1  4  5]\n",
      " [ 0  0  0  0  6  1]\n",
      " [ 0  0  0  6  1  7]\n",
      " [ 0  0  0  0  8  1]\n",
      " [ 0  0  0  8  1  9]\n",
      " [ 0  0  8  1  9 10]\n",
      " [ 0  8  1  9 10  1]\n",
      " [ 8  1  9 10  1 11]]\n"
     ]
    }
   ],
   "source": [
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a83142",
   "metadata": {},
   "source": [
    "padding 방식을 'pre'로 설정함으로써 maxlen보다 짧은 길이의 샘플의 앞을 0으로 채움"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4288fdcb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492ac078",
   "metadata": {},
   "source": [
    "(3) 레이블 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72241a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.array(sequences)\n",
    "X = sequences[:, :-1]\n",
    "y = sequences[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c1102357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  2]\n",
      " [ 0  0  0  2  3]\n",
      " [ 0  0  2  3  1]\n",
      " [ 0  2  3  1  4]\n",
      " [ 0  0  0  0  6]\n",
      " [ 0  0  0  6  1]\n",
      " [ 0  0  0  0  8]\n",
      " [ 0  0  0  8  1]\n",
      " [ 0  0  8  1  9]\n",
      " [ 0  8  1  9 10]\n",
      " [ 8  1  9 10  1]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37ce655d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  1  4  5  1  7  1  9 10  1 11]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59890149",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30efb3a",
   "metadata": {},
   "source": [
    "(4) 원-핫 인코딩 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "168ae181",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee506af",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2241ef9",
   "metadata": {},
   "source": [
    "2. 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "907bbcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16c3a169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/200\n",
      "WARNING:tensorflow:From C:\\Anaconda\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1/1 - 1s - loss: 2.4819 - accuracy: 0.0909 - 1s/epoch - 1s/step\n",
      "Epoch 2/200\n",
      "1/1 - 0s - loss: 2.4653 - accuracy: 0.2727 - 0s/epoch - 0s/step\n",
      "Epoch 3/200\n",
      "1/1 - 0s - loss: 2.4489 - accuracy: 0.4545 - 0s/epoch - 0s/step\n",
      "Epoch 4/200\n",
      "1/1 - 0s - loss: 2.4325 - accuracy: 0.3636 - 0s/epoch - 0s/step\n",
      "Epoch 5/200\n",
      "1/1 - 0s - loss: 2.4159 - accuracy: 0.3636 - 633us/epoch - 633us/step\n",
      "Epoch 6/200\n",
      "1/1 - 0s - loss: 2.3991 - accuracy: 0.3636 - 0s/epoch - 0s/step\n",
      "Epoch 7/200\n",
      "1/1 - 0s - loss: 2.3820 - accuracy: 0.3636 - 0s/epoch - 0s/step\n",
      "Epoch 8/200\n",
      "1/1 - 0s - loss: 2.3645 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 9/200\n",
      "1/1 - 0s - loss: 2.3465 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 10/200\n",
      "1/1 - 0s - loss: 2.3279 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 11/200\n",
      "1/1 - 0s - loss: 2.3087 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 12/200\n",
      "1/1 - 0s - loss: 2.2889 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 13/200\n",
      "1/1 - 0s - loss: 2.2684 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 14/200\n",
      "1/1 - 0s - loss: 2.2473 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 15/200\n",
      "1/1 - 0s - loss: 2.2257 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 16/200\n",
      "1/1 - 0s - loss: 2.2035 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 17/200\n",
      "1/1 - 0s - loss: 2.1810 - accuracy: 0.3636 - 4ms/epoch - 4ms/step\n",
      "Epoch 18/200\n",
      "1/1 - 0s - loss: 2.1582 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 19/200\n",
      "1/1 - 0s - loss: 2.1355 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 20/200\n",
      "1/1 - 0s - loss: 2.1130 - accuracy: 0.3636 - 3ms/epoch - 3ms/step\n",
      "Epoch 21/200\n",
      "1/1 - 0s - loss: 2.0910 - accuracy: 0.3636 - 1ms/epoch - 1ms/step\n",
      "Epoch 22/200\n",
      "1/1 - 0s - loss: 2.0699 - accuracy: 0.3636 - 0s/epoch - 0s/step\n",
      "Epoch 23/200\n",
      "1/1 - 0s - loss: 2.0500 - accuracy: 0.3636 - 0s/epoch - 0s/step\n",
      "Epoch 24/200\n",
      "1/1 - 0s - loss: 2.0314 - accuracy: 0.3636 - 16ms/epoch - 16ms/step\n",
      "Epoch 25/200\n",
      "1/1 - 0s - loss: 2.0144 - accuracy: 0.3636 - 0s/epoch - 0s/step\n",
      "Epoch 26/200\n",
      "1/1 - 0s - loss: 1.9989 - accuracy: 0.3636 - 0s/epoch - 0s/step\n",
      "Epoch 27/200\n",
      "1/1 - 0s - loss: 1.9849 - accuracy: 0.3636 - 16ms/epoch - 16ms/step\n",
      "Epoch 28/200\n",
      "1/1 - 0s - loss: 1.9718 - accuracy: 0.3636 - 0s/epoch - 0s/step\n",
      "Epoch 29/200\n",
      "1/1 - 0s - loss: 1.9594 - accuracy: 0.3636 - 0s/epoch - 0s/step\n",
      "Epoch 30/200\n",
      "1/1 - 0s - loss: 1.9472 - accuracy: 0.3636 - 0s/epoch - 0s/step\n",
      "Epoch 31/200\n",
      "1/1 - 0s - loss: 1.9346 - accuracy: 0.3636 - 0s/epoch - 0s/step\n",
      "Epoch 32/200\n",
      "1/1 - 0s - loss: 1.9213 - accuracy: 0.3636 - 0s/epoch - 0s/step\n",
      "Epoch 33/200\n",
      "1/1 - 0s - loss: 1.9072 - accuracy: 0.3636 - 0s/epoch - 0s/step\n",
      "Epoch 34/200\n",
      "1/1 - 0s - loss: 1.8922 - accuracy: 0.3636 - 16ms/epoch - 16ms/step\n",
      "Epoch 35/200\n",
      "1/1 - 0s - loss: 1.8765 - accuracy: 0.3636 - 0s/epoch - 0s/step\n",
      "Epoch 36/200\n",
      "1/1 - 0s - loss: 1.8604 - accuracy: 0.3636 - 0s/epoch - 0s/step\n",
      "Epoch 37/200\n",
      "1/1 - 0s - loss: 1.8440 - accuracy: 0.3636 - 16ms/epoch - 16ms/step\n",
      "Epoch 38/200\n",
      "1/1 - 0s - loss: 1.8276 - accuracy: 0.3636 - 0s/epoch - 0s/step\n",
      "Epoch 39/200\n",
      "1/1 - 0s - loss: 1.8113 - accuracy: 0.3636 - 16ms/epoch - 16ms/step\n",
      "Epoch 40/200\n",
      "1/1 - 0s - loss: 1.7954 - accuracy: 0.3636 - 0s/epoch - 0s/step\n",
      "Epoch 41/200\n",
      "1/1 - 0s - loss: 1.7797 - accuracy: 0.3636 - 16ms/epoch - 16ms/step\n",
      "Epoch 42/200\n",
      "1/1 - 0s - loss: 1.7643 - accuracy: 0.3636 - 0s/epoch - 0s/step\n",
      "Epoch 43/200\n",
      "1/1 - 0s - loss: 1.7489 - accuracy: 0.3636 - 16ms/epoch - 16ms/step\n",
      "Epoch 44/200\n",
      "1/1 - 0s - loss: 1.7335 - accuracy: 0.3636 - 0s/epoch - 0s/step\n",
      "Epoch 45/200\n",
      "1/1 - 0s - loss: 1.7179 - accuracy: 0.3636 - 0s/epoch - 0s/step\n",
      "Epoch 46/200\n",
      "1/1 - 0s - loss: 1.7018 - accuracy: 0.3636 - 0s/epoch - 0s/step\n",
      "Epoch 47/200\n",
      "1/1 - 0s - loss: 1.6852 - accuracy: 0.3636 - 0s/epoch - 0s/step\n",
      "Epoch 48/200\n",
      "1/1 - 0s - loss: 1.6681 - accuracy: 0.3636 - 16ms/epoch - 16ms/step\n",
      "Epoch 49/200\n",
      "1/1 - 0s - loss: 1.6504 - accuracy: 0.3636 - 0s/epoch - 0s/step\n",
      "Epoch 50/200\n",
      "1/1 - 0s - loss: 1.6321 - accuracy: 0.3636 - 16ms/epoch - 16ms/step\n",
      "Epoch 51/200\n",
      "1/1 - 0s - loss: 1.6133 - accuracy: 0.3636 - 0s/epoch - 0s/step\n",
      "Epoch 52/200\n",
      "1/1 - 0s - loss: 1.5940 - accuracy: 0.4545 - 0s/epoch - 0s/step\n",
      "Epoch 53/200\n",
      "1/1 - 0s - loss: 1.5742 - accuracy: 0.4545 - 16ms/epoch - 16ms/step\n",
      "Epoch 54/200\n",
      "1/1 - 0s - loss: 1.5541 - accuracy: 0.4545 - 0s/epoch - 0s/step\n",
      "Epoch 55/200\n",
      "1/1 - 0s - loss: 1.5335 - accuracy: 0.4545 - 0s/epoch - 0s/step\n",
      "Epoch 56/200\n",
      "1/1 - 0s - loss: 1.5125 - accuracy: 0.5455 - 0s/epoch - 0s/step\n",
      "Epoch 57/200\n",
      "1/1 - 0s - loss: 1.4912 - accuracy: 0.5455 - 0s/epoch - 0s/step\n",
      "Epoch 58/200\n",
      "1/1 - 0s - loss: 1.4695 - accuracy: 0.5455 - 0s/epoch - 0s/step\n",
      "Epoch 59/200\n",
      "1/1 - 0s - loss: 1.4474 - accuracy: 0.5455 - 0s/epoch - 0s/step\n",
      "Epoch 60/200\n",
      "1/1 - 0s - loss: 1.4250 - accuracy: 0.5455 - 0s/epoch - 0s/step\n",
      "Epoch 61/200\n",
      "1/1 - 0s - loss: 1.4022 - accuracy: 0.5455 - 0s/epoch - 0s/step\n",
      "Epoch 62/200\n",
      "1/1 - 0s - loss: 1.3792 - accuracy: 0.5455 - 16ms/epoch - 16ms/step\n",
      "Epoch 63/200\n",
      "1/1 - 0s - loss: 1.3561 - accuracy: 0.6364 - 0s/epoch - 0s/step\n",
      "Epoch 64/200\n",
      "1/1 - 0s - loss: 1.3328 - accuracy: 0.6364 - 0s/epoch - 0s/step\n",
      "Epoch 65/200\n",
      "1/1 - 0s - loss: 1.3096 - accuracy: 0.6364 - 0s/epoch - 0s/step\n",
      "Epoch 66/200\n",
      "1/1 - 0s - loss: 1.2866 - accuracy: 0.6364 - 16ms/epoch - 16ms/step\n",
      "Epoch 67/200\n",
      "1/1 - 0s - loss: 1.2637 - accuracy: 0.6364 - 0s/epoch - 0s/step\n",
      "Epoch 68/200\n",
      "1/1 - 0s - loss: 1.2411 - accuracy: 0.6364 - 0s/epoch - 0s/step\n",
      "Epoch 69/200\n",
      "1/1 - 0s - loss: 1.2188 - accuracy: 0.6364 - 0s/epoch - 0s/step\n",
      "Epoch 70/200\n",
      "1/1 - 0s - loss: 1.1969 - accuracy: 0.6364 - 0s/epoch - 0s/step\n",
      "Epoch 71/200\n",
      "1/1 - 0s - loss: 1.1754 - accuracy: 0.6364 - 0s/epoch - 0s/step\n",
      "Epoch 72/200\n",
      "1/1 - 0s - loss: 1.1542 - accuracy: 0.6364 - 0s/epoch - 0s/step\n",
      "Epoch 73/200\n",
      "1/1 - 0s - loss: 1.1335 - accuracy: 0.7273 - 17ms/epoch - 17ms/step\n",
      "Epoch 74/200\n",
      "1/1 - 0s - loss: 1.1133 - accuracy: 0.7273 - 0s/epoch - 0s/step\n",
      "Epoch 75/200\n",
      "1/1 - 0s - loss: 1.0935 - accuracy: 0.7273 - 0s/epoch - 0s/step\n",
      "Epoch 76/200\n",
      "1/1 - 0s - loss: 1.0741 - accuracy: 0.7273 - 0s/epoch - 0s/step\n",
      "Epoch 77/200\n",
      "1/1 - 0s - loss: 1.0552 - accuracy: 0.7273 - 17ms/epoch - 17ms/step\n",
      "Epoch 78/200\n",
      "1/1 - 0s - loss: 1.0368 - accuracy: 0.7273 - 0s/epoch - 0s/step\n",
      "Epoch 79/200\n",
      "1/1 - 0s - loss: 1.0188 - accuracy: 0.7273 - 0s/epoch - 0s/step\n",
      "Epoch 80/200\n",
      "1/1 - 0s - loss: 1.0013 - accuracy: 0.7273 - 0s/epoch - 0s/step\n",
      "Epoch 81/200\n",
      "1/1 - 0s - loss: 0.9842 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 82/200\n",
      "1/1 - 0s - loss: 0.9675 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 83/200\n",
      "1/1 - 0s - loss: 0.9513 - accuracy: 0.7273 - 0s/epoch - 0s/step\n",
      "Epoch 84/200\n",
      "1/1 - 0s - loss: 0.9354 - accuracy: 0.7273 - 9ms/epoch - 9ms/step\n",
      "Epoch 85/200\n",
      "1/1 - 0s - loss: 0.9200 - accuracy: 0.7273 - 0s/epoch - 0s/step\n",
      "Epoch 86/200\n",
      "1/1 - 0s - loss: 0.9048 - accuracy: 0.7273 - 0s/epoch - 0s/step\n",
      "Epoch 87/200\n",
      "1/1 - 0s - loss: 0.8901 - accuracy: 0.7273 - 0s/epoch - 0s/step\n",
      "Epoch 88/200\n",
      "1/1 - 0s - loss: 0.8757 - accuracy: 0.7273 - 17ms/epoch - 17ms/step\n",
      "Epoch 89/200\n",
      "1/1 - 0s - loss: 0.8616 - accuracy: 0.7273 - 0s/epoch - 0s/step\n",
      "Epoch 90/200\n",
      "1/1 - 0s - loss: 0.8478 - accuracy: 0.7273 - 0s/epoch - 0s/step\n",
      "Epoch 91/200\n",
      "1/1 - 0s - loss: 0.8343 - accuracy: 0.7273 - 0s/epoch - 0s/step\n",
      "Epoch 92/200\n",
      "1/1 - 0s - loss: 0.8211 - accuracy: 0.7273 - 1ms/epoch - 1ms/step\n",
      "Epoch 93/200\n",
      "1/1 - 0s - loss: 0.8082 - accuracy: 0.7273 - 0s/epoch - 0s/step\n",
      "Epoch 94/200\n",
      "1/1 - 0s - loss: 0.7955 - accuracy: 0.7273 - 0s/epoch - 0s/step\n",
      "Epoch 95/200\n",
      "1/1 - 0s - loss: 0.7831 - accuracy: 0.7273 - 0s/epoch - 0s/step\n",
      "Epoch 96/200\n",
      "1/1 - 0s - loss: 0.7709 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 97/200\n",
      "1/1 - 0s - loss: 0.7590 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 98/200\n",
      "1/1 - 0s - loss: 0.7472 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 99/200\n",
      "1/1 - 0s - loss: 0.7356 - accuracy: 0.7273 - 4ms/epoch - 4ms/step\n",
      "Epoch 100/200\n",
      "1/1 - 0s - loss: 0.7243 - accuracy: 0.7273 - 0s/epoch - 0s/step\n",
      "Epoch 101/200\n",
      "1/1 - 0s - loss: 0.7131 - accuracy: 0.7273 - 0s/epoch - 0s/step\n",
      "Epoch 102/200\n",
      "1/1 - 0s - loss: 0.7020 - accuracy: 0.7273 - 0s/epoch - 0s/step\n",
      "Epoch 103/200\n",
      "1/1 - 0s - loss: 0.6912 - accuracy: 0.7273 - 17ms/epoch - 17ms/step\n",
      "Epoch 104/200\n",
      "1/1 - 0s - loss: 0.6804 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 105/200\n",
      "1/1 - 0s - loss: 0.6699 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 106/200\n",
      "1/1 - 0s - loss: 0.6595 - accuracy: 0.7273 - 3ms/epoch - 3ms/step\n",
      "Epoch 107/200\n",
      "1/1 - 0s - loss: 0.6492 - accuracy: 0.7273 - 4ms/epoch - 4ms/step\n",
      "Epoch 108/200\n",
      "1/1 - 0s - loss: 0.6391 - accuracy: 0.8182 - 2ms/epoch - 2ms/step\n",
      "Epoch 109/200\n",
      "1/1 - 0s - loss: 0.6291 - accuracy: 0.8182 - 3ms/epoch - 3ms/step\n",
      "Epoch 110/200\n",
      "1/1 - 0s - loss: 0.6193 - accuracy: 0.8182 - 3ms/epoch - 3ms/step\n",
      "Epoch 111/200\n",
      "1/1 - 0s - loss: 0.6096 - accuracy: 0.8182 - 6ms/epoch - 6ms/step\n",
      "Epoch 112/200\n",
      "1/1 - 0s - loss: 0.6001 - accuracy: 0.8182 - 3ms/epoch - 3ms/step\n",
      "Epoch 113/200\n",
      "1/1 - 0s - loss: 0.5907 - accuracy: 0.8182 - 6ms/epoch - 6ms/step\n",
      "Epoch 114/200\n",
      "1/1 - 0s - loss: 0.5814 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 115/200\n",
      "1/1 - 0s - loss: 0.5723 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
      "Epoch 116/200\n",
      "1/1 - 0s - loss: 0.5633 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
      "Epoch 117/200\n",
      "1/1 - 0s - loss: 0.5545 - accuracy: 0.9091 - 3ms/epoch - 3ms/step\n",
      "Epoch 118/200\n",
      "1/1 - 0s - loss: 0.5457 - accuracy: 0.9091 - 7ms/epoch - 7ms/step\n",
      "Epoch 119/200\n",
      "1/1 - 0s - loss: 0.5372 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 120/200\n",
      "1/1 - 0s - loss: 0.5287 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 121/200\n",
      "1/1 - 0s - loss: 0.5204 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 122/200\n",
      "1/1 - 0s - loss: 0.5122 - accuracy: 0.9091 - 16ms/epoch - 16ms/step\n",
      "Epoch 123/200\n",
      "1/1 - 0s - loss: 0.5041 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 124/200\n",
      "1/1 - 0s - loss: 0.4962 - accuracy: 0.9091 - 12ms/epoch - 12ms/step\n",
      "Epoch 125/200\n",
      "1/1 - 0s - loss: 0.4883 - accuracy: 0.9091 - 6ms/epoch - 6ms/step\n",
      "Epoch 126/200\n",
      "1/1 - 0s - loss: 0.4806 - accuracy: 0.9091 - 4ms/epoch - 4ms/step\n",
      "Epoch 127/200\n",
      "1/1 - 0s - loss: 0.4730 - accuracy: 0.9091 - 3ms/epoch - 3ms/step\n",
      "Epoch 128/200\n",
      "1/1 - 0s - loss: 0.4656 - accuracy: 0.9091 - 5ms/epoch - 5ms/step\n",
      "Epoch 129/200\n",
      "1/1 - 0s - loss: 0.4582 - accuracy: 0.9091 - 3ms/epoch - 3ms/step\n",
      "Epoch 130/200\n",
      "1/1 - 0s - loss: 0.4509 - accuracy: 0.9091 - 3ms/epoch - 3ms/step\n",
      "Epoch 131/200\n",
      "1/1 - 0s - loss: 0.4438 - accuracy: 0.9091 - 3ms/epoch - 3ms/step\n",
      "Epoch 132/200\n",
      "1/1 - 0s - loss: 0.4368 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 133/200\n",
      "1/1 - 0s - loss: 0.4299 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 134/200\n",
      "1/1 - 0s - loss: 0.4231 - accuracy: 0.9091 - 16ms/epoch - 16ms/step\n",
      "Epoch 135/200\n",
      "1/1 - 0s - loss: 0.4164 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 136/200\n",
      "1/1 - 0s - loss: 0.4098 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 137/200\n",
      "1/1 - 0s - loss: 0.4033 - accuracy: 0.9091 - 17ms/epoch - 17ms/step\n",
      "Epoch 138/200\n",
      "1/1 - 0s - loss: 0.3969 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 139/200\n",
      "1/1 - 0s - loss: 0.3906 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 140/200\n",
      "1/1 - 0s - loss: 0.3845 - accuracy: 0.9091 - 17ms/epoch - 17ms/step\n",
      "Epoch 141/200\n",
      "1/1 - 0s - loss: 0.3784 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 142/200\n",
      "1/1 - 0s - loss: 0.3724 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 143/200\n",
      "1/1 - 0s - loss: 0.3666 - accuracy: 0.9091 - 17ms/epoch - 17ms/step\n",
      "Epoch 144/200\n",
      "1/1 - 0s - loss: 0.3608 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 145/200\n",
      "1/1 - 0s - loss: 0.3551 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 146/200\n",
      "1/1 - 0s - loss: 0.3496 - accuracy: 0.9091 - 17ms/epoch - 17ms/step\n",
      "Epoch 147/200\n",
      "1/1 - 0s - loss: 0.3441 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 148/200\n",
      "1/1 - 0s - loss: 0.3388 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 149/200\n",
      "1/1 - 0s - loss: 0.3335 - accuracy: 0.9091 - 16ms/epoch - 16ms/step\n",
      "Epoch 150/200\n",
      "1/1 - 0s - loss: 0.3284 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 151/200\n",
      "1/1 - 0s - loss: 0.3233 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 152/200\n",
      "1/1 - 0s - loss: 0.3184 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 153/200\n",
      "1/1 - 0s - loss: 0.3135 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 154/200\n",
      "1/1 - 0s - loss: 0.3087 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 155/200\n",
      "1/1 - 0s - loss: 0.3041 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 156/200\n",
      "1/1 - 0s - loss: 0.2995 - accuracy: 0.9091 - 2ms/epoch - 2ms/step\n",
      "Epoch 157/200\n",
      "1/1 - 0s - loss: 0.2950 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 158/200\n",
      "1/1 - 0s - loss: 0.2906 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 159/200\n",
      "1/1 - 0s - loss: 0.2863 - accuracy: 0.9091 - 17ms/epoch - 17ms/step\n",
      "Epoch 160/200\n",
      "1/1 - 0s - loss: 0.2821 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 161/200\n",
      "1/1 - 0s - loss: 0.2780 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 162/200\n",
      "1/1 - 0s - loss: 0.2739 - accuracy: 0.9091 - 16ms/epoch - 16ms/step\n",
      "Epoch 163/200\n",
      "1/1 - 0s - loss: 0.2700 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 164/200\n",
      "1/1 - 0s - loss: 0.2661 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 165/200\n",
      "1/1 - 0s - loss: 0.2623 - accuracy: 0.9091 - 17ms/epoch - 17ms/step\n",
      "Epoch 166/200\n",
      "1/1 - 0s - loss: 0.2586 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 167/200\n",
      "1/1 - 0s - loss: 0.2550 - accuracy: 0.9091 - 16ms/epoch - 16ms/step\n",
      "Epoch 168/200\n",
      "1/1 - 0s - loss: 0.2514 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 169/200\n",
      "1/1 - 0s - loss: 0.2479 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 170/200\n",
      "1/1 - 0s - loss: 0.2445 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 171/200\n",
      "1/1 - 0s - loss: 0.2411 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 172/200\n",
      "1/1 - 0s - loss: 0.2378 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 173/200\n",
      "1/1 - 0s - loss: 0.2346 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 174/200\n",
      "1/1 - 0s - loss: 0.2315 - accuracy: 0.9091 - 661us/epoch - 661us/step\n",
      "Epoch 175/200\n",
      "1/1 - 0s - loss: 0.2284 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 176/200\n",
      "1/1 - 0s - loss: 0.2253 - accuracy: 0.9091 - 17ms/epoch - 17ms/step\n",
      "Epoch 177/200\n",
      "1/1 - 0s - loss: 0.2223 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 178/200\n",
      "1/1 - 0s - loss: 0.2194 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 179/200\n",
      "1/1 - 0s - loss: 0.2165 - accuracy: 0.9091 - 16ms/epoch - 16ms/step\n",
      "Epoch 180/200\n",
      "1/1 - 0s - loss: 0.2137 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 181/200\n",
      "1/1 - 0s - loss: 0.2110 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 182/200\n",
      "1/1 - 0s - loss: 0.2082 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 183/200\n",
      "1/1 - 0s - loss: 0.2056 - accuracy: 0.9091 - 527us/epoch - 527us/step\n",
      "Epoch 184/200\n",
      "1/1 - 0s - loss: 0.2030 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 185/200\n",
      "1/1 - 0s - loss: 0.2004 - accuracy: 0.9091 - 15ms/epoch - 15ms/step\n",
      "Epoch 186/200\n",
      "1/1 - 0s - loss: 0.1978 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 187/200\n",
      "1/1 - 0s - loss: 0.1953 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 188/200\n",
      "1/1 - 0s - loss: 0.1929 - accuracy: 0.9091 - 17ms/epoch - 17ms/step\n",
      "Epoch 189/200\n",
      "1/1 - 0s - loss: 0.1905 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 190/200\n",
      "1/1 - 0s - loss: 0.1881 - accuracy: 0.9091 - 0s/epoch - 0s/step\n",
      "Epoch 191/200\n",
      "1/1 - 0s - loss: 0.1857 - accuracy: 1.0000 - 17ms/epoch - 17ms/step\n",
      "Epoch 192/200\n",
      "1/1 - 0s - loss: 0.1834 - accuracy: 1.0000 - 0s/epoch - 0s/step\n",
      "Epoch 193/200\n",
      "1/1 - 0s - loss: 0.1811 - accuracy: 1.0000 - 0s/epoch - 0s/step\n",
      "Epoch 194/200\n",
      "1/1 - 0s - loss: 0.1789 - accuracy: 1.0000 - 16ms/epoch - 16ms/step\n",
      "Epoch 195/200\n",
      "1/1 - 0s - loss: 0.1767 - accuracy: 1.0000 - 0s/epoch - 0s/step\n",
      "Epoch 196/200\n",
      "1/1 - 0s - loss: 0.1745 - accuracy: 1.0000 - 0s/epoch - 0s/step\n",
      "Epoch 197/200\n",
      "1/1 - 0s - loss: 0.1723 - accuracy: 1.0000 - 0s/epoch - 0s/step\n",
      "Epoch 198/200\n",
      "1/1 - 0s - loss: 0.1702 - accuracy: 1.0000 - 1ms/epoch - 1ms/step\n",
      "Epoch 199/200\n",
      "1/1 - 0s - loss: 0.1681 - accuracy: 1.0000 - 0s/epoch - 0s/step\n",
      "Epoch 200/200\n",
      "1/1 - 0s - loss: 0.1660 - accuracy: 1.0000 - 0s/epoch - 0s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1b0b27c9990>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 10\n",
    "hidden_units = 32\n",
    "\n",
    "# 모델 생성\n",
    "model = Sequential()\n",
    "\n",
    "# 임베딩층\n",
    "model.add(Embedding(vocab_size, embedding_dim)) # Embedding(input_dim, output_dim)\n",
    "\n",
    "# 은닉층\n",
    "model.add(SimpleRNN(hidden_units))\n",
    "\n",
    "# 출력층\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "# 컴파일\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X, y, epochs=200, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5463f9",
   "metadata": {},
   "source": [
    "verbose=0 → 출력 정보 X  \n",
    "verbose=0 → 정보를 상세하게 출력  \n",
    "verbose=0 → 정보를 함축적으로 출력  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7faf950f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, tokenizer, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
    "    init_word = current_word\n",
    "    sentence = ''\n",
    "    \n",
    "    for _ in range(n):\n",
    "        # 정수 인코딩 + 패딩\n",
    "        encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
    "        encoded = pad_sequences([encoded], maxlen=5, padding='pre')\n",
    "        \n",
    "        # X : 현재 단어, y : 예측한 단어\n",
    "        result = model.predict(encoded, verbose=0)\n",
    "        result = np.argmax(result, axis=1)\n",
    "        \n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == result:\n",
    "                break\n",
    "                \n",
    "        current_word = current_word + ' ' + word\n",
    "        \n",
    "        sentence = sentence + ' ' + word\n",
    "        \n",
    "    sentence = init_word + sentence\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d20553",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe264dc8",
   "metadata": {},
   "source": [
    "실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "618dbc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경마장에 있는 말이 뛰고 있다\n",
      "그의 말이 법이다\n",
      "가는 말이 고와야 오는 말이 곱다\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, tokenizer, '경마장에', 4))\n",
    "print(sentence_generation(model, tokenizer, '그의', 2))\n",
    "print(sentence_generation(model, tokenizer, '가는', 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e21cc9",
   "metadata": {},
   "source": [
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64e55fd",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc347f2",
   "metadata": {},
   "source": [
    "1. 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da628a33",
   "metadata": {},
   "source": [
    "(1) 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd904b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2aee9339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f396c4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('D:/datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e89b516",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articleID</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>byline</th>\n",
       "      <th>documentType</th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>multimedia</th>\n",
       "      <th>newDesk</th>\n",
       "      <th>printPage</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "      <th>webURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5adf6684068401528a2aa69b</td>\n",
       "      <td>781</td>\n",
       "      <td>By JOHN BRANCH</td>\n",
       "      <td>article</td>\n",
       "      <td>Former N.F.L. Cheerleaders’ Settlement Offer: ...</td>\n",
       "      <td>['Workplace Hazards and Violations', 'Football...</td>\n",
       "      <td>68</td>\n",
       "      <td>Sports</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 17:16:49</td>\n",
       "      <td>Pro Football</td>\n",
       "      <td>“I understand that they could meet with us, pa...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/sports/foot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5adf653f068401528a2aa697</td>\n",
       "      <td>656</td>\n",
       "      <td>By LISA FRIEDMAN</td>\n",
       "      <td>article</td>\n",
       "      <td>E.P.A. to Unveil a New Rule. Its Effect: Less ...</td>\n",
       "      <td>['Environmental Protection Agency', 'Pruitt, S...</td>\n",
       "      <td>68</td>\n",
       "      <td>Climate</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 17:11:21</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>The agency plans to publish a new regulation T...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/climate/epa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5adf4626068401528a2aa628</td>\n",
       "      <td>2427</td>\n",
       "      <td>By PETE WELLS</td>\n",
       "      <td>article</td>\n",
       "      <td>The New Noma, Explained</td>\n",
       "      <td>['Restaurants', 'Noma (Copenhagen, Restaurant)...</td>\n",
       "      <td>66</td>\n",
       "      <td>Dining</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 14:58:44</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>What’s it like to eat at the second incarnatio...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/dining/noma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5adf40d2068401528a2aa619</td>\n",
       "      <td>626</td>\n",
       "      <td>By JULIE HIRSCHFELD DAVIS and PETER BAKER</td>\n",
       "      <td>article</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>['Macron, Emmanuel (1977- )', 'Trump, Donald J...</td>\n",
       "      <td>68</td>\n",
       "      <td>Washington</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 14:35:57</td>\n",
       "      <td>Europe</td>\n",
       "      <td>President Trump welcomed President Emmanuel Ma...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/world/europ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5adf3d64068401528a2aa60f</td>\n",
       "      <td>815</td>\n",
       "      <td>By IAN AUSTEN and DAN BILEFSKY</td>\n",
       "      <td>article</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>['Toronto, Ontario, Attack (April, 2018)', 'Mu...</td>\n",
       "      <td>68</td>\n",
       "      <td>Foreign</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 14:21:21</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Alek Minassian, 25, a resident of Toronto’s Ri...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/world/canad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  articleID  articleWordCount  \\\n",
       "0  5adf6684068401528a2aa69b               781   \n",
       "1  5adf653f068401528a2aa697               656   \n",
       "2  5adf4626068401528a2aa628              2427   \n",
       "3  5adf40d2068401528a2aa619               626   \n",
       "4  5adf3d64068401528a2aa60f               815   \n",
       "\n",
       "                                      byline documentType  \\\n",
       "0                             By JOHN BRANCH      article   \n",
       "1                           By LISA FRIEDMAN      article   \n",
       "2                              By PETE WELLS      article   \n",
       "3  By JULIE HIRSCHFELD DAVIS and PETER BAKER      article   \n",
       "4             By IAN AUSTEN and DAN BILEFSKY      article   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Former N.F.L. Cheerleaders’ Settlement Offer: ...   \n",
       "1  E.P.A. to Unveil a New Rule. Its Effect: Less ...   \n",
       "2                            The New Noma, Explained   \n",
       "3                                            Unknown   \n",
       "4                                            Unknown   \n",
       "\n",
       "                                            keywords  multimedia     newDesk  \\\n",
       "0  ['Workplace Hazards and Violations', 'Football...          68      Sports   \n",
       "1  ['Environmental Protection Agency', 'Pruitt, S...          68     Climate   \n",
       "2  ['Restaurants', 'Noma (Copenhagen, Restaurant)...          66      Dining   \n",
       "3  ['Macron, Emmanuel (1977- )', 'Trump, Donald J...          68  Washington   \n",
       "4  ['Toronto, Ontario, Attack (April, 2018)', 'Mu...          68     Foreign   \n",
       "\n",
       "   printPage              pubDate   sectionName  \\\n",
       "0          0  2018-04-24 17:16:49  Pro Football   \n",
       "1          0  2018-04-24 17:11:21       Unknown   \n",
       "2          0  2018-04-24 14:58:44       Unknown   \n",
       "3          0  2018-04-24 14:35:57        Europe   \n",
       "4          0  2018-04-24 14:21:21        Canada   \n",
       "\n",
       "                                             snippet              source  \\\n",
       "0  “I understand that they could meet with us, pa...  The New York Times   \n",
       "1  The agency plans to publish a new regulation T...  The New York Times   \n",
       "2  What’s it like to eat at the second incarnatio...  The New York Times   \n",
       "3  President Trump welcomed President Emmanuel Ma...  The New York Times   \n",
       "4  Alek Minassian, 25, a resident of Toronto’s Ri...  The New York Times   \n",
       "\n",
       "  typeOfMaterial                                             webURL  \n",
       "0           News  https://www.nytimes.com/2018/04/24/sports/foot...  \n",
       "1           News  https://www.nytimes.com/2018/04/24/climate/epa...  \n",
       "2           News  https://www.nytimes.com/2018/04/24/dining/noma...  \n",
       "3           News  https://www.nytimes.com/2018/04/24/world/europ...  \n",
       "4           News  https://www.nytimes.com/2018/04/24/world/canad...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ArticlesApril2018.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75565a70",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ac25d8",
   "metadata": {},
   "source": [
    "(2) 결측값 확인/제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "804cb6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "열의 개수 :  15\n",
      "Index(['articleID', 'articleWordCount', 'byline', 'documentType', 'headline',\n",
      "       'keywords', 'multimedia', 'newDesk', 'printPage', 'pubDate',\n",
      "       'sectionName', 'snippet', 'source', 'typeOfMaterial', 'webURL'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('열의 개수 : ', len(df.columns))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6141bc62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(df['headline'].isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c18f3f",
   "metadata": {},
   "source": [
    "headline 열에서 결측값이 없다고 확인됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "522e0fd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
       " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
       " 'The New Noma, Explained',\n",
       " 'Unknown',\n",
       " 'Unknown']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline = []\n",
    "\n",
    "headline.extend(list(df.headline.values))\n",
    "headline[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2271255",
   "metadata": {},
   "source": [
    "but, 불필요한 Unknown 값이 있는 걸 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0864c54",
   "metadata": {},
   "source": [
    "<변경 전>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f256dd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 개수 : 1324\n"
     ]
    }
   ],
   "source": [
    "print(\"총 샘플의 개수 : {}\".format(len(headline)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562a4683",
   "metadata": {},
   "source": [
    "<제거 후>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0f25edac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "노이즈값 제거 후 샘플의 개수 : 1214\n"
     ]
    }
   ],
   "source": [
    "headline = [word for word in headline if word != \"Unknown\"]\n",
    "print('노이즈값 제거 후 샘플의 개수 : {}'.format(len(headline)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d1b08e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b729fbc0",
   "metadata": {},
   "source": [
    "(3) 불필요한 특수 문자 확인/제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51edcdef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
       " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
       " 'The New Noma, Explained',\n",
       " 'How a Bag of Texas Dirt  Became a Times Tradition',\n",
       " 'Is School a Place for Self-Expression?']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7a53da",
   "metadata": {},
   "source": [
    "but, 불필요한 특수문자가 포함된 것을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ebe6ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['former nfl cheerleaders settlement offer 1 and a meeting with goodell',\n",
       " 'epa to unveil a new rule its effect less science in policymaking',\n",
       " 'the new noma explained',\n",
       " 'how a bag of texas dirt  became a times tradition',\n",
       " 'is school a place for selfexpression']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def repreprocessing(raw_sentence):\n",
    "    preprocessed_sentence = raw_sentence.encode(\"utf8\").decode(\"ascii\", \"ignore\")\n",
    "    # 구두점 제거 → 소문자화\n",
    "    return ''.join(word for word in preprocessed_sentence if word not in punctuation).lower()\n",
    "\n",
    "preprocessed_headline = [repreprocessing(x) for x in headline]\n",
    "preprocessed_headline[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9264bf",
   "metadata": {},
   "source": [
    "제거"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260b0627",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccd31bd",
   "metadata": {},
   "source": [
    "(4) sequence 형성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "41f7bf1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 3494\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(preprocessed_headline)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('단어 집합의 크기 : %d' %vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "037bd19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[99, 269],\n",
       " [99, 269, 371],\n",
       " [99, 269, 371, 1115],\n",
       " [99, 269, 371, 1115, 582],\n",
       " [99, 269, 371, 1115, 582, 52],\n",
       " [99, 269, 371, 1115, 582, 52, 7],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10, 1116],\n",
       " [100, 3]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = []\n",
    "\n",
    "for sentence in preprocessed_headline:\n",
    "    \n",
    "    encoded = tokenizer.texts_to_sequences([sentence])[0]\n",
    "    \n",
    "    for i in range(1, len(encoded)):\n",
    "        sequence = encoded[:i+1]\n",
    "        sequences.append(sequence)\n",
    "        \n",
    "sequences[:11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7cc81e",
   "metadata": {},
   "source": [
    "Eg.  \n",
    "[99, 269] → former nfl  \n",
    "[99, 269, 371] → former nfl cheerleaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61312bc5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebed215",
   "metadata": {},
   "source": [
    "(5) 어떤 정수가 어떤 단어를 살펴보기 위한 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce52811f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "빈도 수 상의 582번 단어 : offer\n"
     ]
    }
   ],
   "source": [
    "index_to_word = {}\n",
    "for key, value in tokenizer.word_index.items():\n",
    "    index_to_word[value] = key\n",
    "\n",
    "print('빈도 수 상의 582번 단어 : {}'.format(index_to_word[582]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f3b4ee",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b67c9bd",
   "metadata": {},
   "source": [
    "(6) 패딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b27d3b",
   "metadata": {},
   "source": [
    "패딩하기 위해 최대 길이 알아보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2ab234a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플의 최대 길이 : 24\n"
     ]
    }
   ],
   "source": [
    "max_len = max(len(l) for l in sequences)\n",
    "print('샘플의 최대 길이 : {}'.format(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b34fcfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0   99  269]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0   99  269  371]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0   99  269  371 1115]]\n"
     ]
    }
   ],
   "source": [
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
    "print(sequences[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbf9d15",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c73ddb",
   "metadata": {},
   "source": [
    "(7) 레이블 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "298a4467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0  99]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0  99 269]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0  99 269 371]]\n",
      "[ 269  371 1115]\n"
     ]
    }
   ],
   "source": [
    "sequences = np.array(sequences)\n",
    "X = sequences[:, :-1]\n",
    "y = sequences[:, -1]\n",
    "\n",
    "print(X[:3])\n",
    "print(y[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "58b413ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0da40c7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3797f688",
   "metadata": {},
   "source": [
    "2. 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a6fddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0f881d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "244/244 - 4s - loss: 7.6411 - accuracy: 0.0282 - 4s/epoch - 18ms/step\n",
      "Epoch 2/200\n",
      "244/244 - 2s - loss: 7.1113 - accuracy: 0.0295 - 2s/epoch - 9ms/step\n",
      "Epoch 3/200\n",
      "244/244 - 2s - loss: 6.9734 - accuracy: 0.0336 - 2s/epoch - 9ms/step\n",
      "Epoch 4/200\n",
      "244/244 - 2s - loss: 6.8519 - accuracy: 0.0400 - 2s/epoch - 9ms/step\n",
      "Epoch 5/200\n",
      "244/244 - 2s - loss: 6.7072 - accuracy: 0.0454 - 2s/epoch - 9ms/step\n",
      "Epoch 6/200\n",
      "244/244 - 2s - loss: 6.5289 - accuracy: 0.0468 - 2s/epoch - 9ms/step\n",
      "Epoch 7/200\n",
      "244/244 - 2s - loss: 6.3198 - accuracy: 0.0518 - 2s/epoch - 9ms/step\n",
      "Epoch 8/200\n",
      "244/244 - 2s - loss: 6.1072 - accuracy: 0.0587 - 2s/epoch - 9ms/step\n",
      "Epoch 9/200\n",
      "244/244 - 2s - loss: 5.9016 - accuracy: 0.0674 - 2s/epoch - 9ms/step\n",
      "Epoch 10/200\n",
      "244/244 - 2s - loss: 5.7050 - accuracy: 0.0686 - 2s/epoch - 9ms/step\n",
      "Epoch 11/200\n",
      "244/244 - 2s - loss: 5.5227 - accuracy: 0.0724 - 2s/epoch - 9ms/step\n",
      "Epoch 12/200\n",
      "244/244 - 2s - loss: 5.3510 - accuracy: 0.0788 - 2s/epoch - 9ms/step\n",
      "Epoch 13/200\n",
      "244/244 - 2s - loss: 5.1904 - accuracy: 0.0848 - 2s/epoch - 9ms/step\n",
      "Epoch 14/200\n",
      "244/244 - 2s - loss: 5.0380 - accuracy: 0.0891 - 2s/epoch - 9ms/step\n",
      "Epoch 15/200\n",
      "244/244 - 2s - loss: 4.8925 - accuracy: 0.1001 - 2s/epoch - 9ms/step\n",
      "Epoch 16/200\n",
      "244/244 - 2s - loss: 4.7507 - accuracy: 0.1120 - 2s/epoch - 9ms/step\n",
      "Epoch 17/200\n",
      "244/244 - 2s - loss: 4.6145 - accuracy: 0.1289 - 2s/epoch - 9ms/step\n",
      "Epoch 18/200\n",
      "244/244 - 2s - loss: 4.4837 - accuracy: 0.1435 - 2s/epoch - 9ms/step\n",
      "Epoch 19/200\n",
      "244/244 - 2s - loss: 4.3570 - accuracy: 0.1624 - 2s/epoch - 9ms/step\n",
      "Epoch 20/200\n",
      "244/244 - 2s - loss: 4.2324 - accuracy: 0.1798 - 2s/epoch - 9ms/step\n",
      "Epoch 21/200\n",
      "244/244 - 2s - loss: 4.1148 - accuracy: 0.1997 - 2s/epoch - 9ms/step\n",
      "Epoch 22/200\n",
      "244/244 - 2s - loss: 3.9997 - accuracy: 0.2218 - 2s/epoch - 9ms/step\n",
      "Epoch 23/200\n",
      "244/244 - 2s - loss: 3.8888 - accuracy: 0.2356 - 2s/epoch - 9ms/step\n",
      "Epoch 24/200\n",
      "244/244 - 2s - loss: 3.7794 - accuracy: 0.2540 - 2s/epoch - 9ms/step\n",
      "Epoch 25/200\n",
      "244/244 - 2s - loss: 3.6781 - accuracy: 0.2693 - 2s/epoch - 9ms/step\n",
      "Epoch 26/200\n",
      "244/244 - 2s - loss: 3.5752 - accuracy: 0.2881 - 2s/epoch - 9ms/step\n",
      "Epoch 27/200\n",
      "244/244 - 2s - loss: 3.4788 - accuracy: 0.3036 - 2s/epoch - 9ms/step\n",
      "Epoch 28/200\n",
      "244/244 - 2s - loss: 3.3862 - accuracy: 0.3262 - 2s/epoch - 9ms/step\n",
      "Epoch 29/200\n",
      "244/244 - 2s - loss: 3.2951 - accuracy: 0.3405 - 2s/epoch - 9ms/step\n",
      "Epoch 30/200\n",
      "244/244 - 2s - loss: 3.2081 - accuracy: 0.3527 - 2s/epoch - 9ms/step\n",
      "Epoch 31/200\n",
      "244/244 - 2s - loss: 3.1243 - accuracy: 0.3746 - 2s/epoch - 9ms/step\n",
      "Epoch 32/200\n",
      "244/244 - 2s - loss: 3.0434 - accuracy: 0.3883 - 2s/epoch - 9ms/step\n",
      "Epoch 33/200\n",
      "244/244 - 2s - loss: 2.9655 - accuracy: 0.4011 - 2s/epoch - 9ms/step\n",
      "Epoch 34/200\n",
      "244/244 - 2s - loss: 2.8911 - accuracy: 0.4139 - 2s/epoch - 9ms/step\n",
      "Epoch 35/200\n",
      "244/244 - 2s - loss: 2.8169 - accuracy: 0.4243 - 2s/epoch - 9ms/step\n",
      "Epoch 36/200\n",
      "244/244 - 2s - loss: 2.7477 - accuracy: 0.4411 - 2s/epoch - 9ms/step\n",
      "Epoch 37/200\n",
      "244/244 - 2s - loss: 2.6802 - accuracy: 0.4494 - 2s/epoch - 9ms/step\n",
      "Epoch 38/200\n",
      "244/244 - 2s - loss: 2.6171 - accuracy: 0.4653 - 2s/epoch - 9ms/step\n",
      "Epoch 39/200\n",
      "244/244 - 2s - loss: 2.5496 - accuracy: 0.4758 - 2s/epoch - 9ms/step\n",
      "Epoch 40/200\n",
      "244/244 - 2s - loss: 2.4877 - accuracy: 0.4875 - 2s/epoch - 9ms/step\n",
      "Epoch 41/200\n",
      "244/244 - 2s - loss: 2.4308 - accuracy: 0.5007 - 2s/epoch - 9ms/step\n",
      "Epoch 42/200\n",
      "244/244 - 2s - loss: 2.3708 - accuracy: 0.5078 - 2s/epoch - 9ms/step\n",
      "Epoch 43/200\n",
      "244/244 - 2s - loss: 2.3152 - accuracy: 0.5231 - 2s/epoch - 10ms/step\n",
      "Epoch 44/200\n",
      "244/244 - 2s - loss: 2.2622 - accuracy: 0.5322 - 2s/epoch - 9ms/step\n",
      "Epoch 45/200\n",
      "244/244 - 2s - loss: 2.2081 - accuracy: 0.5452 - 2s/epoch - 9ms/step\n",
      "Epoch 46/200\n",
      "244/244 - 2s - loss: 2.1562 - accuracy: 0.5540 - 2s/epoch - 9ms/step\n",
      "Epoch 47/200\n",
      "244/244 - 2s - loss: 2.1064 - accuracy: 0.5654 - 2s/epoch - 9ms/step\n",
      "Epoch 48/200\n",
      "244/244 - 2s - loss: 2.0577 - accuracy: 0.5739 - 2s/epoch - 9ms/step\n",
      "Epoch 49/200\n",
      "244/244 - 2s - loss: 2.0112 - accuracy: 0.5844 - 2s/epoch - 9ms/step\n",
      "Epoch 50/200\n",
      "244/244 - 2s - loss: 1.9621 - accuracy: 0.5984 - 2s/epoch - 9ms/step\n",
      "Epoch 51/200\n",
      "244/244 - 2s - loss: 1.9188 - accuracy: 0.6048 - 2s/epoch - 9ms/step\n",
      "Epoch 52/200\n",
      "244/244 - 2s - loss: 1.8745 - accuracy: 0.6134 - 2s/epoch - 9ms/step\n",
      "Epoch 53/200\n",
      "244/244 - 2s - loss: 1.8289 - accuracy: 0.6187 - 2s/epoch - 9ms/step\n",
      "Epoch 54/200\n",
      "244/244 - 2s - loss: 1.7868 - accuracy: 0.6303 - 2s/epoch - 9ms/step\n",
      "Epoch 55/200\n",
      "244/244 - 2s - loss: 1.7492 - accuracy: 0.6412 - 2s/epoch - 9ms/step\n",
      "Epoch 56/200\n",
      "244/244 - 2s - loss: 1.7064 - accuracy: 0.6528 - 2s/epoch - 9ms/step\n",
      "Epoch 57/200\n",
      "244/244 - 2s - loss: 1.6654 - accuracy: 0.6573 - 2s/epoch - 9ms/step\n",
      "Epoch 58/200\n",
      "244/244 - 2s - loss: 1.6263 - accuracy: 0.6688 - 2s/epoch - 10ms/step\n",
      "Epoch 59/200\n",
      "244/244 - 2s - loss: 1.5864 - accuracy: 0.6782 - 2s/epoch - 9ms/step\n",
      "Epoch 60/200\n",
      "244/244 - 2s - loss: 1.5516 - accuracy: 0.6828 - 2s/epoch - 9ms/step\n",
      "Epoch 61/200\n",
      "244/244 - 2s - loss: 1.5160 - accuracy: 0.6872 - 2s/epoch - 9ms/step\n",
      "Epoch 62/200\n",
      "244/244 - 2s - loss: 1.4792 - accuracy: 0.6999 - 2s/epoch - 9ms/step\n",
      "Epoch 63/200\n",
      "244/244 - 2s - loss: 1.4428 - accuracy: 0.7049 - 2s/epoch - 9ms/step\n",
      "Epoch 64/200\n",
      "244/244 - 2s - loss: 1.4105 - accuracy: 0.7155 - 2s/epoch - 9ms/step\n",
      "Epoch 65/200\n",
      "244/244 - 2s - loss: 1.3762 - accuracy: 0.7229 - 2s/epoch - 9ms/step\n",
      "Epoch 66/200\n",
      "244/244 - 2s - loss: 1.3496 - accuracy: 0.7250 - 2s/epoch - 9ms/step\n",
      "Epoch 67/200\n",
      "244/244 - 2s - loss: 1.3108 - accuracy: 0.7360 - 2s/epoch - 9ms/step\n",
      "Epoch 68/200\n",
      "244/244 - 2s - loss: 1.2803 - accuracy: 0.7427 - 2s/epoch - 9ms/step\n",
      "Epoch 69/200\n",
      "244/244 - 2s - loss: 1.2512 - accuracy: 0.7489 - 2s/epoch - 9ms/step\n",
      "Epoch 70/200\n",
      "244/244 - 2s - loss: 1.2236 - accuracy: 0.7502 - 2s/epoch - 9ms/step\n",
      "Epoch 71/200\n",
      "244/244 - 2s - loss: 1.1937 - accuracy: 0.7596 - 2s/epoch - 9ms/step\n",
      "Epoch 72/200\n",
      "244/244 - 2s - loss: 1.1675 - accuracy: 0.7634 - 2s/epoch - 10ms/step\n",
      "Epoch 73/200\n",
      "244/244 - 2s - loss: 1.1407 - accuracy: 0.7706 - 2s/epoch - 10ms/step\n",
      "Epoch 74/200\n",
      "244/244 - 2s - loss: 1.1115 - accuracy: 0.7766 - 2s/epoch - 9ms/step\n",
      "Epoch 75/200\n",
      "244/244 - 2s - loss: 1.0851 - accuracy: 0.7811 - 2s/epoch - 9ms/step\n",
      "Epoch 76/200\n",
      "244/244 - 2s - loss: 1.0629 - accuracy: 0.7889 - 2s/epoch - 9ms/step\n",
      "Epoch 77/200\n",
      "244/244 - 2s - loss: 1.0372 - accuracy: 0.7934 - 2s/epoch - 9ms/step\n",
      "Epoch 78/200\n",
      "244/244 - 2s - loss: 1.0154 - accuracy: 0.7973 - 2s/epoch - 9ms/step\n",
      "Epoch 79/200\n",
      "244/244 - 2s - loss: 0.9892 - accuracy: 0.8011 - 2s/epoch - 9ms/step\n",
      "Epoch 80/200\n",
      "244/244 - 2s - loss: 0.9686 - accuracy: 0.8070 - 2s/epoch - 9ms/step\n",
      "Epoch 81/200\n",
      "244/244 - 2s - loss: 0.9427 - accuracy: 0.8117 - 2s/epoch - 9ms/step\n",
      "Epoch 82/200\n",
      "244/244 - 2s - loss: 0.9225 - accuracy: 0.8124 - 2s/epoch - 9ms/step\n",
      "Epoch 83/200\n",
      "244/244 - 2s - loss: 0.9009 - accuracy: 0.8208 - 2s/epoch - 9ms/step\n",
      "Epoch 84/200\n",
      "244/244 - 2s - loss: 0.8808 - accuracy: 0.8234 - 2s/epoch - 9ms/step\n",
      "Epoch 85/200\n",
      "244/244 - 2s - loss: 0.8631 - accuracy: 0.8258 - 2s/epoch - 9ms/step\n",
      "Epoch 86/200\n",
      "244/244 - 2s - loss: 0.8447 - accuracy: 0.8326 - 2s/epoch - 9ms/step\n",
      "Epoch 87/200\n",
      "244/244 - 2s - loss: 0.8244 - accuracy: 0.8351 - 2s/epoch - 9ms/step\n",
      "Epoch 88/200\n",
      "244/244 - 2s - loss: 0.8054 - accuracy: 0.8384 - 2s/epoch - 9ms/step\n",
      "Epoch 89/200\n",
      "244/244 - 2s - loss: 0.7883 - accuracy: 0.8430 - 2s/epoch - 9ms/step\n",
      "Epoch 90/200\n",
      "244/244 - 2s - loss: 0.7709 - accuracy: 0.8440 - 2s/epoch - 9ms/step\n",
      "Epoch 91/200\n",
      "244/244 - 2s - loss: 0.7546 - accuracy: 0.8502 - 2s/epoch - 9ms/step\n",
      "Epoch 92/200\n",
      "244/244 - 2s - loss: 0.7438 - accuracy: 0.8552 - 2s/epoch - 9ms/step\n",
      "Epoch 93/200\n",
      "244/244 - 2s - loss: 0.7233 - accuracy: 0.8545 - 2s/epoch - 9ms/step\n",
      "Epoch 94/200\n",
      "244/244 - 2s - loss: 0.7065 - accuracy: 0.8586 - 2s/epoch - 9ms/step\n",
      "Epoch 95/200\n",
      "244/244 - 2s - loss: 0.6915 - accuracy: 0.8594 - 2s/epoch - 9ms/step\n",
      "Epoch 96/200\n",
      "244/244 - 2s - loss: 0.6768 - accuracy: 0.8654 - 2s/epoch - 9ms/step\n",
      "Epoch 97/200\n",
      "244/244 - 2s - loss: 0.6605 - accuracy: 0.8675 - 2s/epoch - 9ms/step\n",
      "Epoch 98/200\n",
      "244/244 - 2s - loss: 0.6474 - accuracy: 0.8697 - 2s/epoch - 9ms/step\n",
      "Epoch 99/200\n",
      "244/244 - 2s - loss: 0.6334 - accuracy: 0.8725 - 2s/epoch - 9ms/step\n",
      "Epoch 100/200\n",
      "244/244 - 2s - loss: 0.6221 - accuracy: 0.8747 - 2s/epoch - 9ms/step\n",
      "Epoch 101/200\n",
      "244/244 - 2s - loss: 0.6122 - accuracy: 0.8763 - 2s/epoch - 9ms/step\n",
      "Epoch 102/200\n",
      "244/244 - 2s - loss: 0.5941 - accuracy: 0.8788 - 2s/epoch - 9ms/step\n",
      "Epoch 103/200\n",
      "244/244 - 2s - loss: 0.5833 - accuracy: 0.8836 - 2s/epoch - 9ms/step\n",
      "Epoch 104/200\n",
      "244/244 - 2s - loss: 0.5731 - accuracy: 0.8839 - 2s/epoch - 9ms/step\n",
      "Epoch 105/200\n",
      "244/244 - 2s - loss: 0.5602 - accuracy: 0.8856 - 2s/epoch - 9ms/step\n",
      "Epoch 106/200\n",
      "244/244 - 2s - loss: 0.5501 - accuracy: 0.8875 - 2s/epoch - 9ms/step\n",
      "Epoch 107/200\n",
      "244/244 - 2s - loss: 0.5400 - accuracy: 0.8900 - 2s/epoch - 9ms/step\n",
      "Epoch 108/200\n",
      "244/244 - 2s - loss: 0.5277 - accuracy: 0.8895 - 2s/epoch - 9ms/step\n",
      "Epoch 109/200\n",
      "244/244 - 2s - loss: 0.5201 - accuracy: 0.8912 - 2s/epoch - 9ms/step\n",
      "Epoch 110/200\n",
      "244/244 - 2s - loss: 0.5098 - accuracy: 0.8944 - 2s/epoch - 9ms/step\n",
      "Epoch 111/200\n",
      "244/244 - 2s - loss: 0.4987 - accuracy: 0.8958 - 2s/epoch - 9ms/step\n",
      "Epoch 112/200\n",
      "244/244 - 2s - loss: 0.4870 - accuracy: 0.8981 - 2s/epoch - 9ms/step\n",
      "Epoch 113/200\n",
      "244/244 - 2s - loss: 0.4794 - accuracy: 0.8993 - 2s/epoch - 9ms/step\n",
      "Epoch 114/200\n",
      "244/244 - 2s - loss: 0.4722 - accuracy: 0.9003 - 2s/epoch - 9ms/step\n",
      "Epoch 115/200\n",
      "244/244 - 2s - loss: 0.4643 - accuracy: 0.9013 - 2s/epoch - 9ms/step\n",
      "Epoch 116/200\n",
      "244/244 - 2s - loss: 0.4547 - accuracy: 0.9022 - 2s/epoch - 9ms/step\n",
      "Epoch 117/200\n",
      "244/244 - 2s - loss: 0.4460 - accuracy: 0.9036 - 2s/epoch - 9ms/step\n",
      "Epoch 118/200\n",
      "244/244 - 2s - loss: 0.4385 - accuracy: 0.9047 - 2s/epoch - 9ms/step\n",
      "Epoch 119/200\n",
      "244/244 - 2s - loss: 0.4330 - accuracy: 0.9079 - 2s/epoch - 9ms/step\n",
      "Epoch 120/200\n",
      "244/244 - 2s - loss: 0.4300 - accuracy: 0.9045 - 2s/epoch - 9ms/step\n",
      "Epoch 121/200\n",
      "244/244 - 2s - loss: 0.4197 - accuracy: 0.9071 - 2s/epoch - 9ms/step\n",
      "Epoch 122/200\n",
      "244/244 - 2s - loss: 0.4102 - accuracy: 0.9089 - 2s/epoch - 9ms/step\n",
      "Epoch 123/200\n",
      "244/244 - 2s - loss: 0.4038 - accuracy: 0.9099 - 2s/epoch - 9ms/step\n",
      "Epoch 124/200\n",
      "244/244 - 2s - loss: 0.3975 - accuracy: 0.9086 - 2s/epoch - 9ms/step\n",
      "Epoch 125/200\n",
      "244/244 - 2s - loss: 0.3916 - accuracy: 0.9103 - 2s/epoch - 9ms/step\n",
      "Epoch 126/200\n",
      "244/244 - 2s - loss: 0.3866 - accuracy: 0.9107 - 2s/epoch - 9ms/step\n",
      "Epoch 127/200\n",
      "244/244 - 2s - loss: 0.3807 - accuracy: 0.9102 - 2s/epoch - 9ms/step\n",
      "Epoch 128/200\n",
      "244/244 - 2s - loss: 0.3765 - accuracy: 0.9134 - 2s/epoch - 9ms/step\n",
      "Epoch 129/200\n",
      "244/244 - 2s - loss: 0.3690 - accuracy: 0.9132 - 2s/epoch - 9ms/step\n",
      "Epoch 130/200\n",
      "244/244 - 2s - loss: 0.3645 - accuracy: 0.9135 - 2s/epoch - 9ms/step\n",
      "Epoch 131/200\n",
      "244/244 - 2s - loss: 0.3605 - accuracy: 0.9132 - 2s/epoch - 9ms/step\n",
      "Epoch 132/200\n",
      "244/244 - 2s - loss: 0.3570 - accuracy: 0.9135 - 2s/epoch - 9ms/step\n",
      "Epoch 133/200\n",
      "244/244 - 2s - loss: 0.3570 - accuracy: 0.9134 - 2s/epoch - 9ms/step\n",
      "Epoch 134/200\n",
      "244/244 - 2s - loss: 0.3565 - accuracy: 0.9126 - 2s/epoch - 9ms/step\n",
      "Epoch 135/200\n",
      "244/244 - 2s - loss: 0.3771 - accuracy: 0.9084 - 2s/epoch - 9ms/step\n",
      "Epoch 136/200\n",
      "244/244 - 2s - loss: 0.3458 - accuracy: 0.9132 - 2s/epoch - 9ms/step\n",
      "Epoch 137/200\n",
      "244/244 - 2s - loss: 0.3363 - accuracy: 0.9140 - 2s/epoch - 9ms/step\n",
      "Epoch 138/200\n",
      "244/244 - 2s - loss: 0.3314 - accuracy: 0.9146 - 2s/epoch - 9ms/step\n",
      "Epoch 139/200\n",
      "244/244 - 2s - loss: 0.3273 - accuracy: 0.9155 - 2s/epoch - 9ms/step\n",
      "Epoch 140/200\n",
      "244/244 - 2s - loss: 0.3244 - accuracy: 0.9154 - 2s/epoch - 9ms/step\n",
      "Epoch 141/200\n",
      "244/244 - 2s - loss: 0.3224 - accuracy: 0.9139 - 2s/epoch - 9ms/step\n",
      "Epoch 142/200\n",
      "244/244 - 2s - loss: 0.3204 - accuracy: 0.9159 - 2s/epoch - 9ms/step\n",
      "Epoch 143/200\n",
      "244/244 - 2s - loss: 0.3174 - accuracy: 0.9149 - 2s/epoch - 9ms/step\n",
      "Epoch 144/200\n",
      "244/244 - 2s - loss: 0.3151 - accuracy: 0.9154 - 2s/epoch - 9ms/step\n",
      "Epoch 145/200\n",
      "244/244 - 2s - loss: 0.3120 - accuracy: 0.9149 - 2s/epoch - 9ms/step\n",
      "Epoch 146/200\n",
      "244/244 - 2s - loss: 0.3110 - accuracy: 0.9154 - 2s/epoch - 9ms/step\n",
      "Epoch 147/200\n",
      "244/244 - 2s - loss: 0.3073 - accuracy: 0.9166 - 2s/epoch - 9ms/step\n",
      "Epoch 148/200\n",
      "244/244 - 2s - loss: 0.3054 - accuracy: 0.9152 - 2s/epoch - 9ms/step\n",
      "Epoch 149/200\n",
      "244/244 - 2s - loss: 0.3063 - accuracy: 0.9162 - 2s/epoch - 9ms/step\n",
      "Epoch 150/200\n",
      "244/244 - 2s - loss: 0.3038 - accuracy: 0.9170 - 2s/epoch - 9ms/step\n",
      "Epoch 151/200\n",
      "244/244 - 2s - loss: 0.3223 - accuracy: 0.9132 - 2s/epoch - 9ms/step\n",
      "Epoch 152/200\n",
      "244/244 - 2s - loss: 0.3049 - accuracy: 0.9158 - 2s/epoch - 9ms/step\n",
      "Epoch 153/200\n",
      "244/244 - 2s - loss: 0.2985 - accuracy: 0.9144 - 2s/epoch - 9ms/step\n",
      "Epoch 154/200\n",
      "244/244 - 2s - loss: 0.2936 - accuracy: 0.9163 - 2s/epoch - 9ms/step\n",
      "Epoch 155/200\n",
      "244/244 - 2s - loss: 0.2914 - accuracy: 0.9166 - 2s/epoch - 9ms/step\n",
      "Epoch 156/200\n",
      "244/244 - 2s - loss: 0.2909 - accuracy: 0.9153 - 2s/epoch - 9ms/step\n",
      "Epoch 157/200\n",
      "244/244 - 2s - loss: 0.2897 - accuracy: 0.9157 - 2s/epoch - 9ms/step\n",
      "Epoch 158/200\n",
      "244/244 - 2s - loss: 0.2882 - accuracy: 0.9157 - 2s/epoch - 9ms/step\n",
      "Epoch 159/200\n",
      "244/244 - 2s - loss: 0.2867 - accuracy: 0.9166 - 2s/epoch - 9ms/step\n",
      "Epoch 160/200\n",
      "244/244 - 2s - loss: 0.2851 - accuracy: 0.9159 - 2s/epoch - 9ms/step\n",
      "Epoch 161/200\n",
      "244/244 - 2s - loss: 0.2842 - accuracy: 0.9163 - 2s/epoch - 9ms/step\n",
      "Epoch 162/200\n",
      "244/244 - 2s - loss: 0.2836 - accuracy: 0.9158 - 2s/epoch - 9ms/step\n",
      "Epoch 163/200\n",
      "244/244 - 2s - loss: 0.2813 - accuracy: 0.9164 - 2s/epoch - 9ms/step\n",
      "Epoch 164/200\n",
      "244/244 - 2s - loss: 0.2812 - accuracy: 0.9159 - 2s/epoch - 9ms/step\n",
      "Epoch 165/200\n",
      "244/244 - 2s - loss: 0.2818 - accuracy: 0.9170 - 2s/epoch - 9ms/step\n",
      "Epoch 166/200\n",
      "244/244 - 2s - loss: 0.2811 - accuracy: 0.9167 - 2s/epoch - 9ms/step\n",
      "Epoch 167/200\n",
      "244/244 - 2s - loss: 0.2848 - accuracy: 0.9164 - 2s/epoch - 9ms/step\n",
      "Epoch 168/200\n",
      "244/244 - 2s - loss: 0.2859 - accuracy: 0.9152 - 2s/epoch - 9ms/step\n",
      "Epoch 169/200\n",
      "244/244 - 2s - loss: 0.2877 - accuracy: 0.9148 - 2s/epoch - 9ms/step\n",
      "Epoch 170/200\n",
      "244/244 - 2s - loss: 0.2820 - accuracy: 0.9145 - 2s/epoch - 9ms/step\n",
      "Epoch 171/200\n",
      "244/244 - 2s - loss: 0.2795 - accuracy: 0.9150 - 2s/epoch - 9ms/step\n",
      "Epoch 172/200\n",
      "244/244 - 2s - loss: 0.2750 - accuracy: 0.9159 - 2s/epoch - 9ms/step\n",
      "Epoch 173/200\n",
      "244/244 - 2s - loss: 0.2730 - accuracy: 0.9167 - 2s/epoch - 9ms/step\n",
      "Epoch 174/200\n",
      "244/244 - 2s - loss: 0.2715 - accuracy: 0.9161 - 2s/epoch - 9ms/step\n",
      "Epoch 175/200\n",
      "244/244 - 2s - loss: 0.2714 - accuracy: 0.9154 - 2s/epoch - 9ms/step\n",
      "Epoch 176/200\n",
      "244/244 - 2s - loss: 0.2706 - accuracy: 0.9155 - 2s/epoch - 9ms/step\n",
      "Epoch 177/200\n",
      "244/244 - 2s - loss: 0.2704 - accuracy: 0.9161 - 2s/epoch - 9ms/step\n",
      "Epoch 178/200\n",
      "244/244 - 2s - loss: 0.2695 - accuracy: 0.9162 - 2s/epoch - 9ms/step\n",
      "Epoch 179/200\n",
      "244/244 - 2s - loss: 0.2696 - accuracy: 0.9161 - 2s/epoch - 9ms/step\n",
      "Epoch 180/200\n",
      "244/244 - 2s - loss: 0.2673 - accuracy: 0.9177 - 2s/epoch - 9ms/step\n",
      "Epoch 181/200\n",
      "244/244 - 2s - loss: 0.2730 - accuracy: 0.9157 - 2s/epoch - 9ms/step\n",
      "Epoch 182/200\n",
      "244/244 - 2s - loss: 0.2724 - accuracy: 0.9145 - 2s/epoch - 9ms/step\n",
      "Epoch 183/200\n",
      "244/244 - 2s - loss: 0.2889 - accuracy: 0.9121 - 2s/epoch - 9ms/step\n",
      "Epoch 184/200\n",
      "244/244 - 2s - loss: 0.2757 - accuracy: 0.9171 - 2s/epoch - 9ms/step\n",
      "Epoch 185/200\n",
      "244/244 - 2s - loss: 0.2683 - accuracy: 0.9167 - 2s/epoch - 9ms/step\n",
      "Epoch 186/200\n",
      "244/244 - 2s - loss: 0.2648 - accuracy: 0.9157 - 2s/epoch - 9ms/step\n",
      "Epoch 187/200\n",
      "244/244 - 2s - loss: 0.2648 - accuracy: 0.9162 - 2s/epoch - 9ms/step\n",
      "Epoch 188/200\n",
      "244/244 - 2s - loss: 0.2647 - accuracy: 0.9161 - 2s/epoch - 9ms/step\n",
      "Epoch 189/200\n",
      "244/244 - 2s - loss: 0.2632 - accuracy: 0.9158 - 2s/epoch - 9ms/step\n",
      "Epoch 190/200\n",
      "244/244 - 2s - loss: 0.2645 - accuracy: 0.9166 - 2s/epoch - 9ms/step\n",
      "Epoch 191/200\n",
      "244/244 - 2s - loss: 0.2636 - accuracy: 0.9158 - 2s/epoch - 9ms/step\n",
      "Epoch 192/200\n",
      "244/244 - 2s - loss: 0.2635 - accuracy: 0.9157 - 2s/epoch - 9ms/step\n",
      "Epoch 193/200\n",
      "244/244 - 2s - loss: 0.2633 - accuracy: 0.9150 - 2s/epoch - 9ms/step\n",
      "Epoch 194/200\n",
      "244/244 - 2s - loss: 0.2700 - accuracy: 0.9155 - 2s/epoch - 9ms/step\n",
      "Epoch 195/200\n",
      "244/244 - 2s - loss: 0.2653 - accuracy: 0.9162 - 2s/epoch - 9ms/step\n",
      "Epoch 196/200\n",
      "244/244 - 2s - loss: 0.2624 - accuracy: 0.9172 - 2s/epoch - 9ms/step\n",
      "Epoch 197/200\n",
      "244/244 - 2s - loss: 0.2614 - accuracy: 0.9159 - 2s/epoch - 9ms/step\n",
      "Epoch 198/200\n",
      "244/244 - 2s - loss: 0.2617 - accuracy: 0.9154 - 2s/epoch - 9ms/step\n",
      "Epoch 199/200\n",
      "244/244 - 2s - loss: 0.2616 - accuracy: 0.9150 - 2s/epoch - 9ms/step\n",
      "Epoch 200/200\n",
      "244/244 - 2s - loss: 0.2606 - accuracy: 0.9164 - 2s/epoch - 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1b0b27c8050>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 10\n",
    "hidden_units = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(LSTM(hidden_units))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2052a072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, tokenizer, current_word, n):\n",
    "    init_word = current_word\n",
    "    sentence = ''\n",
    "    \n",
    "    for _ in range(n):\n",
    "        encoded = tokenizer.texts_to_sequences([current_word])[0]\n",
    "        encoded = pad_sequences([encoded], maxlen=max_len-1, padding='pre')\n",
    "        \n",
    "        result = model.predict(encoded, verbose=0)\n",
    "        result = np.argmax(result, axis=1)\n",
    "        \n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == result:\n",
    "                break\n",
    "                \n",
    "        current_word = current_word + ' ' + word\n",
    "        sentence = sentence + ' ' + word\n",
    "        \n",
    "    sentence = init_word + sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9141c971",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e267bb3",
   "metadata": {},
   "source": [
    "실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e210c88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i disapprove of school vouchers can i still apply for them\n",
      "how to make facebook more accountable in turnaround you sorry national\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, tokenizer, 'i', 10))\n",
    "print(sentence_generation(model, tokenizer, 'how', 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b7c733",
   "metadata": {},
   "source": [
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3672d33",
   "metadata": {},
   "source": [
    "# Char RNNLM(문자 단위 RNN 언어 모델)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a20a9d8",
   "metadata": {},
   "source": [
    "1. 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d91c3e5",
   "metadata": {},
   "source": [
    "(1) 파일 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fe2fe5b6-964c-41a8-992b-617ccbe46c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "86c8321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib.request\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "urllib.request.urlretrieve(\"http://www.gutenberg.org/files/11/11-0.txt\", filename=\"11-0.txt\")\n",
    "\n",
    "f = open('11-0.txt', 'rb')\n",
    "sentences = []\n",
    "for sentence in f:\n",
    "    sentence = sentence.strip() # 공백 제거\n",
    "    sentence = sentence.lower() # 소문자화\n",
    "    sentence = sentence.decode('ascii', 'ignore') # ascii 문자로 디코딩 및 오류 무시\n",
    "    \n",
    "    if len(sentence) > 0:\n",
    "        sentences.append(sentence)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efcc8c2",
   "metadata": {},
   "source": [
    "잘 됐는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "44a5bfe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"*** start of the project gutenberg ebook alice's adventures in\",\n",
       " 'wonderland ***',\n",
       " '[illustration]',\n",
       " 'alices adventures in wonderland',\n",
       " 'by lewis carroll']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ad346e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자열의 길이 또는 총 문자의 개수 : 140323\n"
     ]
    }
   ],
   "source": [
    "total_data = ' '.join(sentences)\n",
    "print('문자열의 길이 또는 총 문자의 개수 : %d' %len(total_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "65448ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** start of the project gutenberg ebook alice's adventures in wonderland *** [illustration] alices adventures in wonderland by lewis carroll the millennium fulcrum edition 3.0 contents chapter i.    \n"
     ]
    }
   ],
   "source": [
    "print(total_data[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf58731-0540-4a14-be8f-1838a3b34e3b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1816c034-b11f-4b4a-8367-09306ccf4d55",
   "metadata": {},
   "source": [
    "(2) 문자-index, index-문자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fa45a2ee-f9d9-4bd6-941c-aeee680f74b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자 집합의 크기 : 43\n"
     ]
    }
   ],
   "source": [
    "char_vocab = sorted(list(set(total_data)))\n",
    "vocab_size = len(char_vocab)\n",
    "print('문자 집합의 크기 : {}'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f785ed72-609e-461d-9a6b-81bd2dab0b88",
   "metadata": {},
   "source": [
    "26개의 알파벳을 포함하여 총 43개의 문자가 있는 것을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a87659d1-cd0e-46d0-b7d2-87415b3aba92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자 집합 :  {' ': 0, '!': 1, \"'\": 2, '(': 3, ')': 4, '*': 5, ',': 6, '-': 7, '.': 8, '0': 9, '3': 10, ':': 11, ';': 12, '?': 13, '[': 14, ']': 15, '_': 16, 'a': 17, 'b': 18, 'c': 19, 'd': 20, 'e': 21, 'f': 22, 'g': 23, 'h': 24, 'i': 25, 'j': 26, 'k': 27, 'l': 28, 'm': 29, 'n': 30, 'o': 31, 'p': 32, 'q': 33, 'r': 34, 's': 35, 't': 36, 'u': 37, 'v': 38, 'w': 39, 'x': 40, 'y': 41, 'z': 42}\n"
     ]
    }
   ],
   "source": [
    "char_to_index = dict((char, index) for index, char in enumerate(char_vocab))\n",
    "print('문자 집합 : ', char_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "76a3640d-1514-446d-8335-52be97b5d7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_char = {}\n",
    "for key, value in char_to_index.items():\n",
    "    index_to_char[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7e1d364e-1ff3-436b-b6ae-382159c5c928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index_to_char {0: ' ', 1: '!', 2: \"'\", 3: '(', 4: ')', 5: '*', 6: ',', 7: '-', 8: '.', 9: '0', 10: '3', 11: ':', 12: ';', 13: '?', 14: '[', 15: ']', 16: '_', 17: 'a', 18: 'b', 19: 'c', 20: 'd', 21: 'e', 22: 'f', 23: 'g', 24: 'h', 25: 'i', 26: 'j', 27: 'k', 28: 'l', 29: 'm', 30: 'n', 31: 'o', 32: 'p', 33: 'q', 34: 'r', 35: 's', 36: 't', 37: 'u', 38: 'v', 39: 'w', 40: 'x', 41: 'y', 42: 'z'}\n"
     ]
    }
   ],
   "source": [
    "print('index_to_char', index_to_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52000745-3f56-4cd7-aebc-c0752270e5c3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9687b4-abcb-40b6-9071-a7f60ca544e2",
   "metadata": {},
   "source": [
    "(3) 훈련 데이터 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "98124014-eb31-4fd0-9a1f-1a532ba4fc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = 'appl'\n",
    "train_y = 'pple'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7d6e47-1826-42e7-a4d0-ef24e77d346b",
   "metadata": {},
   "source": [
    "appl을 통해서 pple를 예측하고자 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9460860a-22b0-405f-97a6-bc9640786506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "만들 수 있는 샘플의 수 : 2338\n"
     ]
    }
   ],
   "source": [
    "seq_length = 60\n",
    "\n",
    "n_samples = int(np.floor((len(total_data) - 1) / seq_length))\n",
    "print('만들 수 있는 샘플의 수 : {}'.format(n_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "789f7410-fd88-4722-8fae-c6bb29eadd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = []\n",
    "train_y = []\n",
    "\n",
    "for i in range(n_samples):\n",
    "    X_sample = total_data[i * seq_length : (i+1) * seq_length]\n",
    "    X_encoded = [char_to_index[c] for c in X_sample]\n",
    "    train_X.append(X_encoded)\n",
    "\n",
    "    y_sample = total_data[i * seq_length + 1 : (i+1) * seq_length + 1]\n",
    "    y_encoded = [char_to_index[c] for c in y_sample]\n",
    "    train_y.append(y_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6059d2-e69f-45f0-ad36-4b3c7f8362c3",
   "metadata": {},
   "source": [
    "문자를 index로 인코딩해서 sample 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "793a54e2-6e7f-456f-8959-6a19f40b06b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X 데이터의 첫 번째 샘플 (인코딩) :  [5, 5, 5, 0, 35, 36, 17, 34, 36, 0, 31, 22, 0, 36, 24, 21, 0, 32, 34, 31, 26, 21, 19, 36, 0, 23, 37, 36, 21, 30, 18, 21, 34, 23, 0, 21, 18, 31, 31, 27, 0, 17, 28, 25, 19, 21, 2, 35, 0, 17, 20, 38, 21, 30, 36, 37, 34, 21, 35, 0]\n",
      "y 데이터의 첫 번째 샘플 (인코딩) :  [5, 5, 0, 35, 36, 17, 34, 36, 0, 31, 22, 0, 36, 24, 21, 0, 32, 34, 31, 26, 21, 19, 36, 0, 23, 37, 36, 21, 30, 18, 21, 34, 23, 0, 21, 18, 31, 31, 27, 0, 17, 28, 25, 19, 21, 2, 35, 0, 17, 20, 38, 21, 30, 36, 37, 34, 21, 35, 0, 25]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "X 데이터의 첫 번째 샘플 (디코딩) :  ['*', '*', '*', ' ', 's', 't', 'a', 'r', 't', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'p', 'r', 'o', 'j', 'e', 'c', 't', ' ', 'g', 'u', 't', 'e', 'n', 'b', 'e', 'r', 'g', ' ', 'e', 'b', 'o', 'o', 'k', ' ', 'a', 'l', 'i', 'c', 'e', \"'\", 's', ' ', 'a', 'd', 'v', 'e', 'n', 't', 'u', 'r', 'e', 's', ' ']\n",
      "y 데이터의 첫 번째 샘플 (디코딩) :  ['*', '*', ' ', 's', 't', 'a', 'r', 't', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'p', 'r', 'o', 'j', 'e', 'c', 't', ' ', 'g', 'u', 't', 'e', 'n', 'b', 'e', 'r', 'g', ' ', 'e', 'b', 'o', 'o', 'k', ' ', 'a', 'l', 'i', 'c', 'e', \"'\", 's', ' ', 'a', 'd', 'v', 'e', 'n', 't', 'u', 'r', 'e', 's', ' ', 'i']\n"
     ]
    }
   ],
   "source": [
    "print('X 데이터의 첫 번째 샘플 (인코딩) : ', train_X[0])\n",
    "print('y 데이터의 첫 번째 샘플 (인코딩) : ', train_y[0])\n",
    "print('-' * 150)\n",
    "print('X 데이터의 첫 번째 샘플 (디코딩) : ', [index_to_char[i] for i in train_X[0]])\n",
    "print('y 데이터의 첫 번째 샘플 (디코딩) : ', [index_to_char[i] for i in train_y[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b2367b5c-c5d8-4cc8-a358-dd177be3fc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25, 30, 0, 39, 31, 30, 20, 21, 34, 28, 17, 30, 20, 0, 5, 5, 5, 0, 14, 25, 28, 28, 37, 35, 36, 34, 17, 36, 25, 31, 30, 15, 0, 17, 28, 25, 19, 21, 35, 0, 17, 20, 38, 21, 30, 36, 37, 34, 21, 35, 0, 25, 30, 0, 39, 31, 30, 20, 21, 34]\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "[30, 0, 39, 31, 30, 20, 21, 34, 28, 17, 30, 20, 0, 5, 5, 5, 0, 14, 25, 28, 28, 37, 35, 36, 34, 17, 36, 25, 31, 30, 15, 0, 17, 28, 25, 19, 21, 35, 0, 17, 20, 38, 21, 30, 36, 37, 34, 21, 35, 0, 25, 30, 0, 39, 31, 30, 20, 21, 34, 28]\n"
     ]
    }
   ],
   "source": [
    "print(train_X[1])\n",
    "print('-' * 150)\n",
    "print(train_y[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3b107b-5083-404a-a7c3-ed18e3594d6d",
   "metadata": {},
   "source": [
    "X에서 오른쪽으로 한 칸 이동한 것이 y가 되도록 인코딩 완료"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e89b82b-0d79-4daa-9d5b-da37d167a050",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc34448-6d58-42fd-89e1-5f8440175f44",
   "metadata": {},
   "source": [
    "(4) 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "25682795-1270-4684-8d1c-6994c88dfbca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X의 크기(shape) : (2338, 60, 43)\n",
      "train_y의 크기(shape) : (2338, 60, 43)\n"
     ]
    }
   ],
   "source": [
    "train_X = to_categorical(train_X)\n",
    "train_y = to_categorical(train_y)\n",
    "\n",
    "print('train_X의 크기(shape) : {}'.format(train_X.shape))\n",
    "print('train_y의 크기(shape) : {}'.format(train_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6525da-9760-4f89-a821-317cd22c1852",
   "metadata": {},
   "source": [
    "<img src=\"https://wikidocs.net/images/page/22886/rnn_image6between7.PNG\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff230f8-6c02-49ee-98a8-d198448d57b0",
   "metadata": {},
   "source": [
    "X와 y의 구조를 살펴보면 그림과 같음!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c075a8-15f5-42b4-b110-4267d6ee3608",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bd3188-3ccb-41c0-bab1-baa7c4d1f425",
   "metadata": {},
   "source": [
    "2. 모델 설계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7ec0e6-6614-4118-9790-2690b78154b4",
   "metadata": {},
   "source": [
    "TimeDistributed를 이용해서 다대다 구조를 만들 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2e266ce3-5cbc-43ab-bd70-016274d8ab92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "74/74 - 9s - loss: 3.0266 - accuracy: 0.1851 - 9s/epoch - 124ms/step\n",
      "Epoch 2/80\n",
      "74/74 - 5s - loss: 2.6890 - accuracy: 0.2605 - 5s/epoch - 72ms/step\n",
      "Epoch 3/80\n",
      "74/74 - 5s - loss: 2.3494 - accuracy: 0.3372 - 5s/epoch - 74ms/step\n",
      "Epoch 4/80\n",
      "74/74 - 6s - loss: 2.1910 - accuracy: 0.3752 - 6s/epoch - 77ms/step\n",
      "Epoch 5/80\n",
      "74/74 - 6s - loss: 2.0887 - accuracy: 0.4020 - 6s/epoch - 77ms/step\n",
      "Epoch 6/80\n",
      "74/74 - 5s - loss: 2.0079 - accuracy: 0.4219 - 5s/epoch - 74ms/step\n",
      "Epoch 7/80\n",
      "74/74 - 5s - loss: 1.9350 - accuracy: 0.4411 - 5s/epoch - 74ms/step\n",
      "Epoch 8/80\n",
      "74/74 - 5s - loss: 1.8724 - accuracy: 0.4569 - 5s/epoch - 72ms/step\n",
      "Epoch 9/80\n",
      "74/74 - 5s - loss: 1.8224 - accuracy: 0.4708 - 5s/epoch - 72ms/step\n",
      "Epoch 10/80\n",
      "74/74 - 5s - loss: 1.7732 - accuracy: 0.4829 - 5s/epoch - 72ms/step\n",
      "Epoch 11/80\n",
      "74/74 - 5s - loss: 1.7266 - accuracy: 0.4938 - 5s/epoch - 72ms/step\n",
      "Epoch 12/80\n",
      "74/74 - 5s - loss: 1.6838 - accuracy: 0.5061 - 5s/epoch - 72ms/step\n",
      "Epoch 13/80\n",
      "74/74 - 5s - loss: 1.6411 - accuracy: 0.5172 - 5s/epoch - 72ms/step\n",
      "Epoch 14/80\n",
      "74/74 - 5s - loss: 1.6037 - accuracy: 0.5273 - 5s/epoch - 73ms/step\n",
      "Epoch 15/80\n",
      "74/74 - 5s - loss: 1.5648 - accuracy: 0.5364 - 5s/epoch - 72ms/step\n",
      "Epoch 16/80\n",
      "74/74 - 5s - loss: 1.5329 - accuracy: 0.5448 - 5s/epoch - 72ms/step\n",
      "Epoch 17/80\n",
      "74/74 - 5s - loss: 1.4988 - accuracy: 0.5541 - 5s/epoch - 72ms/step\n",
      "Epoch 18/80\n",
      "74/74 - 5s - loss: 1.4637 - accuracy: 0.5634 - 5s/epoch - 72ms/step\n",
      "Epoch 19/80\n",
      "74/74 - 5s - loss: 1.4324 - accuracy: 0.5720 - 5s/epoch - 72ms/step\n",
      "Epoch 20/80\n",
      "74/74 - 5s - loss: 1.4021 - accuracy: 0.5805 - 5s/epoch - 74ms/step\n",
      "Epoch 21/80\n",
      "74/74 - 5s - loss: 1.3726 - accuracy: 0.5895 - 5s/epoch - 73ms/step\n",
      "Epoch 22/80\n",
      "74/74 - 5s - loss: 1.3413 - accuracy: 0.5983 - 5s/epoch - 73ms/step\n",
      "Epoch 23/80\n",
      "74/74 - 6s - loss: 1.3123 - accuracy: 0.6069 - 6s/epoch - 75ms/step\n",
      "Epoch 24/80\n",
      "74/74 - 6s - loss: 1.2854 - accuracy: 0.6146 - 6s/epoch - 77ms/step\n",
      "Epoch 25/80\n",
      "74/74 - 6s - loss: 1.2507 - accuracy: 0.6244 - 6s/epoch - 76ms/step\n",
      "Epoch 26/80\n",
      "74/74 - 6s - loss: 1.2236 - accuracy: 0.6319 - 6s/epoch - 80ms/step\n",
      "Epoch 27/80\n",
      "74/74 - 6s - loss: 1.1952 - accuracy: 0.6397 - 6s/epoch - 75ms/step\n",
      "Epoch 28/80\n",
      "74/74 - 6s - loss: 1.1671 - accuracy: 0.6488 - 6s/epoch - 78ms/step\n",
      "Epoch 29/80\n",
      "74/74 - 6s - loss: 1.1404 - accuracy: 0.6563 - 6s/epoch - 77ms/step\n",
      "Epoch 30/80\n",
      "74/74 - 6s - loss: 1.1078 - accuracy: 0.6673 - 6s/epoch - 81ms/step\n",
      "Epoch 31/80\n",
      "74/74 - 6s - loss: 1.0749 - accuracy: 0.6771 - 6s/epoch - 79ms/step\n",
      "Epoch 32/80\n",
      "74/74 - 6s - loss: 1.0486 - accuracy: 0.6848 - 6s/epoch - 81ms/step\n",
      "Epoch 33/80\n",
      "74/74 - 6s - loss: 1.0197 - accuracy: 0.6936 - 6s/epoch - 83ms/step\n",
      "Epoch 34/80\n",
      "74/74 - 6s - loss: 0.9866 - accuracy: 0.7048 - 6s/epoch - 81ms/step\n",
      "Epoch 35/80\n",
      "74/74 - 6s - loss: 0.9601 - accuracy: 0.7124 - 6s/epoch - 79ms/step\n",
      "Epoch 36/80\n",
      "74/74 - 6s - loss: 0.9354 - accuracy: 0.7199 - 6s/epoch - 77ms/step\n",
      "Epoch 37/80\n",
      "74/74 - 6s - loss: 0.8997 - accuracy: 0.7311 - 6s/epoch - 79ms/step\n",
      "Epoch 38/80\n",
      "74/74 - 6s - loss: 0.8798 - accuracy: 0.7368 - 6s/epoch - 76ms/step\n",
      "Epoch 39/80\n",
      "74/74 - 5s - loss: 0.8510 - accuracy: 0.7461 - 5s/epoch - 74ms/step\n",
      "Epoch 40/80\n",
      "74/74 - 5s - loss: 0.8176 - accuracy: 0.7576 - 5s/epoch - 72ms/step\n",
      "Epoch 41/80\n",
      "74/74 - 5s - loss: 0.7888 - accuracy: 0.7661 - 5s/epoch - 73ms/step\n",
      "Epoch 42/80\n",
      "74/74 - 5s - loss: 0.7629 - accuracy: 0.7745 - 5s/epoch - 72ms/step\n",
      "Epoch 43/80\n",
      "74/74 - 5s - loss: 0.7342 - accuracy: 0.7845 - 5s/epoch - 73ms/step\n",
      "Epoch 44/80\n",
      "74/74 - 5s - loss: 0.7138 - accuracy: 0.7898 - 5s/epoch - 72ms/step\n",
      "Epoch 45/80\n",
      "74/74 - 5s - loss: 0.6798 - accuracy: 0.8012 - 5s/epoch - 72ms/step\n",
      "Epoch 46/80\n",
      "74/74 - 5s - loss: 0.6530 - accuracy: 0.8106 - 5s/epoch - 72ms/step\n",
      "Epoch 47/80\n",
      "74/74 - 5s - loss: 0.6302 - accuracy: 0.8176 - 5s/epoch - 72ms/step\n",
      "Epoch 48/80\n",
      "74/74 - 5s - loss: 0.6088 - accuracy: 0.8238 - 5s/epoch - 72ms/step\n",
      "Epoch 49/80\n",
      "74/74 - 5s - loss: 0.5772 - accuracy: 0.8351 - 5s/epoch - 72ms/step\n",
      "Epoch 50/80\n",
      "74/74 - 5s - loss: 0.5640 - accuracy: 0.8378 - 5s/epoch - 72ms/step\n",
      "Epoch 51/80\n",
      "74/74 - 5s - loss: 0.5370 - accuracy: 0.8469 - 5s/epoch - 72ms/step\n",
      "Epoch 52/80\n",
      "74/74 - 5s - loss: 0.5149 - accuracy: 0.8548 - 5s/epoch - 72ms/step\n",
      "Epoch 53/80\n",
      "74/74 - 5s - loss: 0.5033 - accuracy: 0.8572 - 5s/epoch - 74ms/step\n",
      "Epoch 54/80\n",
      "74/74 - 6s - loss: 0.4677 - accuracy: 0.8707 - 6s/epoch - 77ms/step\n",
      "Epoch 55/80\n",
      "74/74 - 5s - loss: 0.4571 - accuracy: 0.8738 - 5s/epoch - 74ms/step\n",
      "Epoch 56/80\n",
      "74/74 - 6s - loss: 0.4403 - accuracy: 0.8794 - 6s/epoch - 74ms/step\n",
      "Epoch 57/80\n",
      "74/74 - 6s - loss: 0.4211 - accuracy: 0.8848 - 6s/epoch - 85ms/step\n",
      "Epoch 58/80\n",
      "74/74 - 5s - loss: 0.3970 - accuracy: 0.8940 - 5s/epoch - 74ms/step\n",
      "Epoch 59/80\n",
      "74/74 - 6s - loss: 0.3850 - accuracy: 0.8969 - 6s/epoch - 75ms/step\n",
      "Epoch 60/80\n",
      "74/74 - 6s - loss: 0.3713 - accuracy: 0.9010 - 6s/epoch - 74ms/step\n",
      "Epoch 61/80\n",
      "74/74 - 6s - loss: 0.3434 - accuracy: 0.9110 - 6s/epoch - 78ms/step\n",
      "Epoch 62/80\n",
      "74/74 - 6s - loss: 0.3340 - accuracy: 0.9133 - 6s/epoch - 84ms/step\n",
      "Epoch 63/80\n",
      "74/74 - 6s - loss: 0.3147 - accuracy: 0.9207 - 6s/epoch - 82ms/step\n",
      "Epoch 64/80\n",
      "74/74 - 6s - loss: 0.3007 - accuracy: 0.9250 - 6s/epoch - 83ms/step\n",
      "Epoch 65/80\n",
      "74/74 - 5s - loss: 0.2771 - accuracy: 0.9335 - 5s/epoch - 73ms/step\n",
      "Epoch 66/80\n",
      "74/74 - 5s - loss: 0.2715 - accuracy: 0.9343 - 5s/epoch - 73ms/step\n",
      "Epoch 67/80\n",
      "74/74 - 5s - loss: 0.2635 - accuracy: 0.9356 - 5s/epoch - 72ms/step\n",
      "Epoch 68/80\n",
      "74/74 - 5s - loss: 0.2592 - accuracy: 0.9367 - 5s/epoch - 72ms/step\n",
      "Epoch 69/80\n",
      "74/74 - 5s - loss: 0.2571 - accuracy: 0.9361 - 5s/epoch - 72ms/step\n",
      "Epoch 70/80\n",
      "74/74 - 5s - loss: 0.2515 - accuracy: 0.9376 - 5s/epoch - 72ms/step\n",
      "Epoch 71/80\n",
      "74/74 - 5s - loss: 0.2318 - accuracy: 0.9438 - 5s/epoch - 72ms/step\n",
      "Epoch 72/80\n",
      "74/74 - 5s - loss: 0.2067 - accuracy: 0.9522 - 5s/epoch - 72ms/step\n",
      "Epoch 73/80\n",
      "74/74 - 5s - loss: 0.2036 - accuracy: 0.9519 - 5s/epoch - 72ms/step\n",
      "Epoch 74/80\n",
      "74/74 - 5s - loss: 0.1990 - accuracy: 0.9528 - 5s/epoch - 72ms/step\n",
      "Epoch 75/80\n",
      "74/74 - 5s - loss: 0.1835 - accuracy: 0.9572 - 5s/epoch - 72ms/step\n",
      "Epoch 76/80\n",
      "74/74 - 5s - loss: 0.1902 - accuracy: 0.9544 - 5s/epoch - 72ms/step\n",
      "Epoch 77/80\n",
      "74/74 - 5s - loss: 0.1803 - accuracy: 0.9571 - 5s/epoch - 72ms/step\n",
      "Epoch 78/80\n",
      "74/74 - 5s - loss: 0.1883 - accuracy: 0.9542 - 5s/epoch - 72ms/step\n",
      "Epoch 79/80\n",
      "74/74 - 5s - loss: 0.2148 - accuracy: 0.9429 - 5s/epoch - 72ms/step\n",
      "Epoch 80/80\n",
      "74/74 - 5s - loss: 0.2611 - accuracy: 0.9237 - 5s/epoch - 74ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1b0c9342e90>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, TimeDistributed\n",
    "\n",
    "hidden_units = 256\n",
    "\n",
    "# 모델 생성\n",
    "model = Sequential()\n",
    "\n",
    "# LSTM 레이어 쌓기\n",
    "model.add(LSTM(hidden_units, input_shape=(None, train_X.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(hidden_units, return_sequences=True))\n",
    "\n",
    "#\n",
    "model.add(TimeDistributed(Dense(vocab_size, activation='softmax')))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_X, train_y, epochs=80, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780f1416-41cb-4f67-b913-44fce59e7614",
   "metadata": {},
   "source": [
    "LTSM layer를 여러 개를 쌓는 이유는 순차 데이터를 더 잘 표현하기 위함 → 복잡한 시간 의존성을 잘 캐치할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "34fcfcf9-27fc-4349-a819-f0553c7b91fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, length):\n",
    "    ix = [np.random.randint(vocab_size)]\n",
    "\n",
    "    y_char = [index_to_char[ix[-1]]]\n",
    "    print(ix[-1], '번 문자', y_char[-1],'로 예측을 시작!')\n",
    "\n",
    "    X = np.zeros((1, length, vocab_size)) # 높이, 행, 열\n",
    "\n",
    "    for i in range(length):\n",
    "        X[0][i][ix[-1]] = 1\n",
    "        print(index_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(index_to_char[ix[-1]])\n",
    "    return ('').join(y_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4dd22df3-bd52-4887-b184-ab37692c45ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 번 문자 w 로 예측을 시작!\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 882ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "what latitude or longitude as she could not this moment, the funch whole thingch! thought alice. they\n"
     ]
    }
   ],
   "source": [
    "result = sentence_generation(model, 100)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b05d9ca-12d9-4dac-8a9c-bf1e2cb010d5",
   "metadata": {},
   "source": [
    "# ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8683f304-6315-44d5-a7f4-6abb5c9c2bdc",
   "metadata": {},
   "source": [
    "# Char RNN으로 텍스트 생성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244e8d51-85c7-4a02-a336-826809b3ca01",
   "metadata": {},
   "source": [
    "1. 데이터에 대한 이해와 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30500822-f9d4-47bd-bd7c-e8e6fdbe8ac4",
   "metadata": {},
   "source": [
    "(1) 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d9236916-e0a1-49aa-aeb5-d476497d36a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "56537838-0700-4d4a-a408-bd2317f35b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = '''\n",
    "I get on with life as a programmer,\n",
    "I like to contemplate beer.\n",
    "But when I start to daydream,\n",
    "My mind turns straight to wine.\n",
    "\n",
    "Do I love wine more than beer?\n",
    "\n",
    "I like to use words about beer.\n",
    "But when I stop my talking,\n",
    "My mind turns straight to wine.\n",
    "\n",
    "I hate bugs and errors.\n",
    "But I just think back to wine,\n",
    "And I'm happy once again.\n",
    "\n",
    "I like to hang out with programming and depp learning.\n",
    "But when left alone,\n",
    "My mind turns straight to wine.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6eb3838d-648b-4f86-bad2-d0299f561d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I get on with life as a programmer, I like to contemplate beer. But when I start to daydream, My mind turns straight to wine. Do I love wine more than beer? I like to use words about beer. But when I stop my talking, My mind turns straight to wine. I hate bugs and errors. But I just think back to wine, And I'm happy once again. I like to hang out with programming and depp learning. But when left alone, My mind turns straight to wine.\n"
     ]
    }
   ],
   "source": [
    "tokens = raw_text.split() # 공백 기준으로 단어 분리\n",
    "raw_text = ' '.join(tokens) # 단어들 띄어쓰기로 연결\n",
    "print(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b8efba0f-5c80-4d73-9598-cb39d0e34f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문자 집합 :  [' ', \"'\", ',', '.', '?', 'A', 'B', 'D', 'I', 'M', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y']\n",
      "문자 집합의 크기 :  33\n"
     ]
    }
   ],
   "source": [
    "char_vocab = sorted(list(set(raw_text)))\n",
    "vocab_size = len(char_vocab)\n",
    "print('문자 집합 : ', char_vocab)\n",
    "print('문자 집합의 크기 : ', vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602d547c-dfec-4754-ade8-8f5a36108457",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ef7f77-8427-4585-928f-a257aab1fa38",
   "metadata": {},
   "source": [
    "(2) 전처리(토큰화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "837d10f1-d680-4eb6-9d05-e14f54244e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, \"'\": 1, ',': 2, '.': 3, '?': 4, 'A': 5, 'B': 6, 'D': 7, 'I': 8, 'M': 9, 'a': 10, 'b': 11, 'c': 12, 'd': 13, 'e': 14, 'f': 15, 'g': 16, 'h': 17, 'i': 18, 'j': 19, 'k': 20, 'l': 21, 'm': 22, 'n': 23, 'o': 24, 'p': 25, 'r': 26, 's': 27, 't': 28, 'u': 29, 'v': 30, 'w': 31, 'y': 32}\n"
     ]
    }
   ],
   "source": [
    "char_to_index = dict((char, index) for index, char in enumerate(char_vocab))\n",
    "print(char_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d595c01-c8f5-41ca-b6e7-83b88d72800a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74916836-189f-4773-95ed-8e3352f5cc8d",
   "metadata": {},
   "source": [
    "(3) 샘플 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f01e245a-7994-485b-989a-70593fe5855c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 훈련 샘플의 수 : 426\n"
     ]
    }
   ],
   "source": [
    "length = 11\n",
    "sequences = []\n",
    "for i in range(length, len(raw_text)):\n",
    "    seq = raw_text[i-length : i]\n",
    "    sequences.append(seq)\n",
    "print('총 훈련 샘플의 수 : %d' %len(sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5b3bf1-69f9-4bb2-8051-87af17e14526",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46c8ff8-d99f-4592-aaf6-c6d58f26fb27",
   "metadata": {},
   "source": [
    "(4) 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7aba1210-1528-42c0-bb48-a01e3dc30487",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sequences = []\n",
    "\n",
    "for sequence in sequences:\n",
    "    encoded_sequence = [char_to_index[char] for char in sequence]\n",
    "    encoded_sequences.append(encoded_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1498a5-96fc-40b6-babc-5386e6919ee3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02915c4-47d3-4b96-a0ba-8dc81cdb7bd6",
   "metadata": {},
   "source": [
    "(5) 레이블 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5e06c401-8cb2-4c9f-bde3-81535c237747",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sequences = np.array(encoded_sequences)\n",
    "\n",
    "X_data = encoded_sequences[:, :-1]\n",
    "y_data = encoded_sequences[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a050bb-ab25-4874-a49a-31b05a08ec3d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6183fb05-58d9-4804-943d-74d9b45b449c",
   "metadata": {},
   "source": [
    "(6) 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d372e6cc-f7b5-452f-83a2-6f85cc6d1991",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_one_hot = [to_categorical(encoded, num_classes=vocab_size) for encoded in X_data]\n",
    "X_data_one_hot = np.array(X_data_one_hot)\n",
    "\n",
    "y_data_one_hot = to_categorical(y_data, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f17dec2c-796e-4a6e-93a2-fffd19ad8fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 10, 33)\n"
     ]
    }
   ],
   "source": [
    "print(X_data_one_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd17f65-d3a7-485c-92d1-4e154a7213df",
   "metadata": {},
   "source": [
    "<img src=\"https://wikidocs.net/images/page/22886/rnn_image6between7.PNG\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b57614d-8a38-4771-afa2-2a379b4f0684",
   "metadata": {},
   "source": [
    "그림으로 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "35026543-3ae0-460a-807b-b56d62a2a168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "abccb12b-3d39-4e29-944f-9ed2f26d9fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ff08075a-9f4a-40ba-907b-b99eae7654f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_data_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9b9243a0-a4bc-4fc2-89ff-c1a1bd560e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_data_one_hot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25b2a8e-6d12-4f72-b314-f51cb84b0a61",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306acff0-d4e5-41c7-a236-6acf614abb79",
   "metadata": {},
   "source": [
    "2. 모델 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a9a18c4f-5eb0-4c9c-9ffa-49350deee2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "56fd1204-c804-4510-afed-12e5a3c89ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 - 2s - loss: 3.4674 - accuracy: 0.1221 - 2s/epoch - 151ms/step\n",
      "Epoch 2/100\n",
      "14/14 - 0s - loss: 3.3741 - accuracy: 0.1972 - 47ms/epoch - 3ms/step\n",
      "Epoch 3/100\n",
      "14/14 - 0s - loss: 3.1487 - accuracy: 0.1972 - 31ms/epoch - 2ms/step\n",
      "Epoch 4/100\n",
      "14/14 - 0s - loss: 3.0123 - accuracy: 0.1972 - 31ms/epoch - 2ms/step\n",
      "Epoch 5/100\n",
      "14/14 - 0s - loss: 2.9611 - accuracy: 0.1972 - 31ms/epoch - 2ms/step\n",
      "Epoch 6/100\n",
      "14/14 - 0s - loss: 2.9407 - accuracy: 0.1972 - 47ms/epoch - 3ms/step\n",
      "Epoch 7/100\n",
      "14/14 - 0s - loss: 2.9210 - accuracy: 0.1972 - 31ms/epoch - 2ms/step\n",
      "Epoch 8/100\n",
      "14/14 - 0s - loss: 2.9018 - accuracy: 0.1972 - 47ms/epoch - 3ms/step\n",
      "Epoch 9/100\n",
      "14/14 - 0s - loss: 2.8785 - accuracy: 0.1972 - 31ms/epoch - 2ms/step\n",
      "Epoch 10/100\n",
      "14/14 - 0s - loss: 2.8416 - accuracy: 0.2019 - 47ms/epoch - 3ms/step\n",
      "Epoch 11/100\n",
      "14/14 - 0s - loss: 2.8184 - accuracy: 0.1948 - 31ms/epoch - 2ms/step\n",
      "Epoch 12/100\n",
      "14/14 - 0s - loss: 2.7651 - accuracy: 0.2066 - 47ms/epoch - 3ms/step\n",
      "Epoch 13/100\n",
      "14/14 - 0s - loss: 2.7272 - accuracy: 0.2066 - 31ms/epoch - 2ms/step\n",
      "Epoch 14/100\n",
      "14/14 - 0s - loss: 2.6693 - accuracy: 0.2160 - 47ms/epoch - 3ms/step\n",
      "Epoch 15/100\n",
      "14/14 - 0s - loss: 2.6147 - accuracy: 0.2160 - 31ms/epoch - 2ms/step\n",
      "Epoch 16/100\n",
      "14/14 - 0s - loss: 2.5884 - accuracy: 0.2559 - 47ms/epoch - 3ms/step\n",
      "Epoch 17/100\n",
      "14/14 - 0s - loss: 2.5347 - accuracy: 0.2700 - 31ms/epoch - 2ms/step\n",
      "Epoch 18/100\n",
      "14/14 - 0s - loss: 2.4882 - accuracy: 0.3075 - 47ms/epoch - 3ms/step\n",
      "Epoch 19/100\n",
      "14/14 - 0s - loss: 2.4447 - accuracy: 0.2746 - 31ms/epoch - 2ms/step\n",
      "Epoch 20/100\n",
      "14/14 - 0s - loss: 2.4027 - accuracy: 0.3239 - 31ms/epoch - 2ms/step\n",
      "Epoch 21/100\n",
      "14/14 - 0s - loss: 2.3513 - accuracy: 0.3075 - 31ms/epoch - 2ms/step\n",
      "Epoch 22/100\n",
      "14/14 - 0s - loss: 2.3129 - accuracy: 0.3404 - 31ms/epoch - 2ms/step\n",
      "Epoch 23/100\n",
      "14/14 - 0s - loss: 2.2979 - accuracy: 0.3239 - 39ms/epoch - 3ms/step\n",
      "Epoch 24/100\n",
      "14/14 - 0s - loss: 2.2385 - accuracy: 0.3756 - 31ms/epoch - 2ms/step\n",
      "Epoch 25/100\n",
      "14/14 - 0s - loss: 2.1842 - accuracy: 0.3732 - 47ms/epoch - 3ms/step\n",
      "Epoch 26/100\n",
      "14/14 - 0s - loss: 2.1622 - accuracy: 0.3826 - 31ms/epoch - 2ms/step\n",
      "Epoch 27/100\n",
      "14/14 - 0s - loss: 2.1115 - accuracy: 0.4014 - 47ms/epoch - 3ms/step\n",
      "Epoch 28/100\n",
      "14/14 - 0s - loss: 2.0743 - accuracy: 0.4155 - 31ms/epoch - 2ms/step\n",
      "Epoch 29/100\n",
      "14/14 - 0s - loss: 2.0225 - accuracy: 0.4437 - 31ms/epoch - 2ms/step\n",
      "Epoch 30/100\n",
      "14/14 - 0s - loss: 1.9996 - accuracy: 0.4249 - 31ms/epoch - 2ms/step\n",
      "Epoch 31/100\n",
      "14/14 - 0s - loss: 1.9670 - accuracy: 0.4272 - 31ms/epoch - 2ms/step\n",
      "Epoch 32/100\n",
      "14/14 - 0s - loss: 1.9074 - accuracy: 0.4906 - 31ms/epoch - 2ms/step\n",
      "Epoch 33/100\n",
      "14/14 - 0s - loss: 1.8904 - accuracy: 0.4624 - 31ms/epoch - 2ms/step\n",
      "Epoch 34/100\n",
      "14/14 - 0s - loss: 1.8456 - accuracy: 0.4859 - 47ms/epoch - 3ms/step\n",
      "Epoch 35/100\n",
      "14/14 - 0s - loss: 1.8101 - accuracy: 0.5047 - 31ms/epoch - 2ms/step\n",
      "Epoch 36/100\n",
      "14/14 - 0s - loss: 1.7520 - accuracy: 0.5235 - 40ms/epoch - 3ms/step\n",
      "Epoch 37/100\n",
      "14/14 - 0s - loss: 1.7309 - accuracy: 0.5305 - 47ms/epoch - 3ms/step\n",
      "Epoch 38/100\n",
      "14/14 - 0s - loss: 1.6805 - accuracy: 0.5540 - 31ms/epoch - 2ms/step\n",
      "Epoch 39/100\n",
      "14/14 - 0s - loss: 1.6276 - accuracy: 0.5728 - 47ms/epoch - 3ms/step\n",
      "Epoch 40/100\n",
      "14/14 - 0s - loss: 1.6072 - accuracy: 0.5681 - 31ms/epoch - 2ms/step\n",
      "Epoch 41/100\n",
      "14/14 - 0s - loss: 1.5582 - accuracy: 0.5798 - 31ms/epoch - 2ms/step\n",
      "Epoch 42/100\n",
      "14/14 - 0s - loss: 1.5413 - accuracy: 0.5939 - 31ms/epoch - 2ms/step\n",
      "Epoch 43/100\n",
      "14/14 - 0s - loss: 1.4814 - accuracy: 0.6221 - 31ms/epoch - 2ms/step\n",
      "Epoch 44/100\n",
      "14/14 - 0s - loss: 1.4532 - accuracy: 0.6103 - 47ms/epoch - 3ms/step\n",
      "Epoch 45/100\n",
      "14/14 - 0s - loss: 1.4132 - accuracy: 0.6502 - 31ms/epoch - 2ms/step\n",
      "Epoch 46/100\n",
      "14/14 - 0s - loss: 1.3960 - accuracy: 0.6432 - 31ms/epoch - 2ms/step\n",
      "Epoch 47/100\n",
      "14/14 - 0s - loss: 1.3435 - accuracy: 0.6690 - 31ms/epoch - 2ms/step\n",
      "Epoch 48/100\n",
      "14/14 - 0s - loss: 1.3068 - accuracy: 0.6620 - 39ms/epoch - 3ms/step\n",
      "Epoch 49/100\n",
      "14/14 - 0s - loss: 1.2939 - accuracy: 0.6761 - 31ms/epoch - 2ms/step\n",
      "Epoch 50/100\n",
      "14/14 - 0s - loss: 1.2473 - accuracy: 0.6995 - 31ms/epoch - 2ms/step\n",
      "Epoch 51/100\n",
      "14/14 - 0s - loss: 1.2211 - accuracy: 0.7042 - 62ms/epoch - 4ms/step\n",
      "Epoch 52/100\n",
      "14/14 - 0s - loss: 1.2017 - accuracy: 0.7160 - 62ms/epoch - 4ms/step\n",
      "Epoch 53/100\n",
      "14/14 - 0s - loss: 1.1544 - accuracy: 0.7066 - 31ms/epoch - 2ms/step\n",
      "Epoch 54/100\n",
      "14/14 - 0s - loss: 1.1321 - accuracy: 0.7066 - 47ms/epoch - 3ms/step\n",
      "Epoch 55/100\n",
      "14/14 - 0s - loss: 1.1083 - accuracy: 0.7230 - 31ms/epoch - 2ms/step\n",
      "Epoch 56/100\n",
      "14/14 - 0s - loss: 1.0629 - accuracy: 0.7347 - 47ms/epoch - 3ms/step\n",
      "Epoch 57/100\n",
      "14/14 - 0s - loss: 1.0220 - accuracy: 0.7629 - 47ms/epoch - 3ms/step\n",
      "Epoch 58/100\n",
      "14/14 - 0s - loss: 1.0169 - accuracy: 0.7371 - 47ms/epoch - 3ms/step\n",
      "Epoch 59/100\n",
      "14/14 - 0s - loss: 0.9774 - accuracy: 0.7653 - 31ms/epoch - 2ms/step\n",
      "Epoch 60/100\n",
      "14/14 - 0s - loss: 0.9401 - accuracy: 0.7793 - 47ms/epoch - 3ms/step\n",
      "Epoch 61/100\n",
      "14/14 - 0s - loss: 0.9075 - accuracy: 0.7887 - 31ms/epoch - 2ms/step\n",
      "Epoch 62/100\n",
      "14/14 - 0s - loss: 0.8923 - accuracy: 0.7817 - 31ms/epoch - 2ms/step\n",
      "Epoch 63/100\n",
      "14/14 - 0s - loss: 0.8736 - accuracy: 0.7840 - 31ms/epoch - 2ms/step\n",
      "Epoch 64/100\n",
      "14/14 - 0s - loss: 0.8374 - accuracy: 0.8075 - 31ms/epoch - 2ms/step\n",
      "Epoch 65/100\n",
      "14/14 - 0s - loss: 0.8251 - accuracy: 0.8286 - 31ms/epoch - 2ms/step\n",
      "Epoch 66/100\n",
      "14/14 - 0s - loss: 0.8103 - accuracy: 0.8122 - 31ms/epoch - 2ms/step\n",
      "Epoch 67/100\n",
      "14/14 - 0s - loss: 0.7861 - accuracy: 0.8192 - 47ms/epoch - 3ms/step\n",
      "Epoch 68/100\n",
      "14/14 - 0s - loss: 0.7546 - accuracy: 0.8333 - 31ms/epoch - 2ms/step\n",
      "Epoch 69/100\n",
      "14/14 - 0s - loss: 0.7220 - accuracy: 0.8474 - 47ms/epoch - 3ms/step\n",
      "Epoch 70/100\n",
      "14/14 - 0s - loss: 0.7202 - accuracy: 0.8357 - 31ms/epoch - 2ms/step\n",
      "Epoch 71/100\n",
      "14/14 - 0s - loss: 0.6791 - accuracy: 0.8568 - 47ms/epoch - 3ms/step\n",
      "Epoch 72/100\n",
      "14/14 - 0s - loss: 0.6441 - accuracy: 0.8850 - 31ms/epoch - 2ms/step\n",
      "Epoch 73/100\n",
      "14/14 - 0s - loss: 0.6327 - accuracy: 0.8756 - 47ms/epoch - 3ms/step\n",
      "Epoch 74/100\n",
      "14/14 - 0s - loss: 0.6138 - accuracy: 0.8944 - 31ms/epoch - 2ms/step\n",
      "Epoch 75/100\n",
      "14/14 - 0s - loss: 0.6016 - accuracy: 0.8897 - 47ms/epoch - 3ms/step\n",
      "Epoch 76/100\n",
      "14/14 - 0s - loss: 0.5680 - accuracy: 0.9108 - 31ms/epoch - 2ms/step\n",
      "Epoch 77/100\n",
      "14/14 - 0s - loss: 0.5540 - accuracy: 0.9038 - 47ms/epoch - 3ms/step\n",
      "Epoch 78/100\n",
      "14/14 - 0s - loss: 0.5371 - accuracy: 0.9108 - 31ms/epoch - 2ms/step\n",
      "Epoch 79/100\n",
      "14/14 - 0s - loss: 0.5319 - accuracy: 0.9272 - 47ms/epoch - 3ms/step\n",
      "Epoch 80/100\n",
      "14/14 - 0s - loss: 0.5341 - accuracy: 0.9296 - 31ms/epoch - 2ms/step\n",
      "Epoch 81/100\n",
      "14/14 - 0s - loss: 0.5077 - accuracy: 0.9178 - 47ms/epoch - 3ms/step\n",
      "Epoch 82/100\n",
      "14/14 - 0s - loss: 0.4711 - accuracy: 0.9413 - 31ms/epoch - 2ms/step\n",
      "Epoch 83/100\n",
      "14/14 - 0s - loss: 0.4652 - accuracy: 0.9366 - 33ms/epoch - 2ms/step\n",
      "Epoch 84/100\n",
      "14/14 - 0s - loss: 0.4403 - accuracy: 0.9531 - 31ms/epoch - 2ms/step\n",
      "Epoch 85/100\n",
      "14/14 - 0s - loss: 0.4159 - accuracy: 0.9507 - 31ms/epoch - 2ms/step\n",
      "Epoch 86/100\n",
      "14/14 - 0s - loss: 0.4120 - accuracy: 0.9601 - 31ms/epoch - 2ms/step\n",
      "Epoch 87/100\n",
      "14/14 - 0s - loss: 0.4088 - accuracy: 0.9437 - 31ms/epoch - 2ms/step\n",
      "Epoch 88/100\n",
      "14/14 - 0s - loss: 0.3902 - accuracy: 0.9554 - 47ms/epoch - 3ms/step\n",
      "Epoch 89/100\n",
      "14/14 - 0s - loss: 0.3822 - accuracy: 0.9601 - 31ms/epoch - 2ms/step\n",
      "Epoch 90/100\n",
      "14/14 - 0s - loss: 0.3756 - accuracy: 0.9601 - 47ms/epoch - 3ms/step\n",
      "Epoch 91/100\n",
      "14/14 - 0s - loss: 0.3560 - accuracy: 0.9671 - 31ms/epoch - 2ms/step\n",
      "Epoch 92/100\n",
      "14/14 - 0s - loss: 0.3492 - accuracy: 0.9624 - 47ms/epoch - 3ms/step\n",
      "Epoch 93/100\n",
      "14/14 - 0s - loss: 0.3308 - accuracy: 0.9718 - 31ms/epoch - 2ms/step\n",
      "Epoch 94/100\n",
      "14/14 - 0s - loss: 0.3227 - accuracy: 0.9695 - 47ms/epoch - 3ms/step\n",
      "Epoch 95/100\n",
      "14/14 - 0s - loss: 0.3138 - accuracy: 0.9648 - 31ms/epoch - 2ms/step\n",
      "Epoch 96/100\n",
      "14/14 - 0s - loss: 0.3056 - accuracy: 0.9671 - 47ms/epoch - 3ms/step\n",
      "Epoch 97/100\n",
      "14/14 - 0s - loss: 0.2980 - accuracy: 0.9695 - 31ms/epoch - 2ms/step\n",
      "Epoch 98/100\n",
      "14/14 - 0s - loss: 0.2907 - accuracy: 0.9742 - 47ms/epoch - 3ms/step\n",
      "Epoch 99/100\n",
      "14/14 - 0s - loss: 0.2842 - accuracy: 0.9765 - 31ms/epoch - 2ms/step\n",
      "Epoch 100/100\n",
      "14/14 - 0s - loss: 0.2718 - accuracy: 0.9695 - 47ms/epoch - 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1b0bda30050>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_units = 64\n",
    "\n",
    "model = Sequential() # 모델 생성\n",
    "model.add(LSTM(hidden_units, input_shape=(X_data_one_hot.shape[1], X_data_one_hot.shape[2]))) # 은닉층\n",
    "model.add(Dense(vocab_size, activation='softmax')) # 전결합층\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # 다중클래스 분류\n",
    "\n",
    "model.fit(X_data_one_hot, y_data_one_hot, epochs=100, verbose=2) # 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e4f69e-856b-4451-b70f-c17a2fc23546",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b57138-3831-40f1-90b8-32056ef97181",
   "metadata": {},
   "source": [
    "3. 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "67665250-a150-4305-90a5-108db3fbdb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, char_to_index, seq_length, seed_text, n):\n",
    "\n",
    "    init_text = seed_text\n",
    "    sentence = ''\n",
    "\n",
    "    for _ in range(n):\n",
    "        encoded = [char_to_index[char] for char in seed_text] # 정수 인코딩\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, padding='pre') # 패딩\n",
    "        encoded = to_categorical(encoded, num_classes=len(char_to_index)) # 원-핫\n",
    "\n",
    "        result = model.predict(encoded, verbose=0) \n",
    "        result = np.argmax(result, axis=1)\n",
    "\n",
    "        for char, index in char_to_index.items():\n",
    "            if index == result:\n",
    "                break\n",
    "\n",
    "        seed_text = seed_text + char\n",
    "\n",
    "        sentence = sentence + char\n",
    "\n",
    "    sentence = init_text + sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "93e6f204-a746-487e-95a0-5bfd18fc873e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I get on with laoerr, s mik ttooann, Mymiind turn sstraight to wine. I hate bugs and error\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, char_to_index, 10 , 'I get on w', 80))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
